## Назад -> [!Algem](!Algem.md)

## Сингулярное представление линейного оtображения

### Введение %% внутривенное %%
Ранее было показано, что изометрическое отображение переводит любой ОНБ в ОНБ. Очевидно, что для произвольного линейного оператора такое не обязательно выполняется.

Можно ли для данного отображения $f: L_1 \mapsto L_2$ в $L_1$ подобрать такой ОНБ, который переводится в ортогональную систему векторов $L_2$?

Пусть существует такой базис $u_1, u_2, u_3$. Тогда $b_1 = f(u_1), b_2 = f(u_2), b_3 = f(u_3)$, $b_1, b_2, b_3$ - ортогональны. Если теперь поделить $b_1, b_2, b_3$ на длины, то получим ортонормированную систему векторов $v_1, v_2, v_3$. Тогда получим числа $\sigma_1, \sigma_2, \sigma_3$ такие, что $f(u_1) = \sigma_1v_1,\ f(u_2) = \sigma_2v_2,\ f(u_3) = \sigma_3v_3$. Это похоже на самосопряжённый оператор. ![](attachments/Pasted%20image%2020230404140048.png)

Для каждого отображения $f$ можно рассмотреть отображение $f\circ f^*$. Это отображение самосопряжённое.

### Лемма
**Лемма**
%% чат гпт %%Бро, понимаешь, есть два пространства $L_1$ и $L_2$, они конечномерные и со скалярным произведением. И есть еще одно отображение $f$, которое линейное и переводит векторы из $L_1$ в $L_2$. Тогда $\ker f\circ f^* = \ker f$

**Доказательство**
$\implies$. Пусть $x \in \ker f$, то есть $f(x) = 0$. Тогда $(f\circ f^)(x) = f^*(f(x)) = f^*(0) = 0 \implies x \in \ker f^*$.

$\impliedby$. Пусть $x\in \ker f \circ f^*$. Тогда рассмотрим $(f(x), f(x)) = (x, f^*(f(x))$ $= (x, (f\circ f^*)(x)) = (x, 0) = 0$

**Следствие**
$\text{r}(f)$ - ранг оператора $f$.
Тогда $\text{r }(f) = \text{r}(f^*)$.

**Доказательство следствия**
По теореме о размерности ядра и образа (о ранге и дефекте) линейного оператора, $\text{r}(f) + \dim\ker f = r(f\circ f^*) + \dim\ker (f\circ f^*) = \dim L_1$. Тогда размерности образов этих преобразований равны.


### Теорема о сингулярном разложении
**Теорема**
Пусть $L_1$, $L_2$ - конечномерные пространства со скалярным произведением, $f: L_1 \mapsto L_2$, $f$ ненулевое. Пусть $m = \dim L_1$, $n = \dim L_2$, $r$ - ранг отображения $f$. Тогда существуют ОНБ $u_1, u_2, \dots, u_n$ в $L_1$ и ОНБ $v_1, \dots, v_n$ в $L_2$ такие, что $\begin{cases} f(u_i) = \sigma_iv_i &|\ 1 \leq i \leq r \\ f(u_i) = 0 & |\ r < i \leq m\end{cases}$. При этом числа $\sigma_i$ определены однозначно и не зависят от выбора базиса $u_1, \dots, u_m$. При этом числа $\sigma_i$ называются ==сингулярными числами== оператора.

**Доказательство**
$f\circ f^* : L_1\mapsto L_1$ - самосопряжённый оператор, так как $(f\circ f^*)^* = (f^*)^* \circ (f^*) = f\circ f^*$. Поэтому в $L_1$ существует ОНБ $u_1, u_2, \dots, u_n$ из собственных векторов оператора $f\circ f^*$. Тогда по доказанному выше следствию $\,r(f\circ f^*) = \,r(f) = \,r$. При этом только $\,r$ собственных чисел отличны от нуля. Пусть $a_1, \dots, a_m$ - собственные числа данных собственных векторов. Пусть $f(u_i) = z_i\ (i = 1\dots m)$. Тогда $(z_i, z_j) = (f(u_i), f(u_j) = (u_i, f^*(f(u_j))) =$ $(u_i, (f\circ f^*)(u_j)) = (u_j, \bar a_ju_j) = \bar a_j(u_i, u_j)) = 0$. Тогда $(z_i, z_j)\neq 0 \implies z_i \neq 0$.
При $i = j$ $(z_i, z_j) = a_i(u_i, u_i) = a_i$. $a_i = (z_i, z_i) = |z_i|^2$. Тогда $\sigma_i = \sqrt{a_i} = |z_i|$. Тогда $v_i = \dfrac{z_i}{|z_i|} \implies v_i = \dfrac{1}{\sigma_i}z_i$. Получили, что $v_1, \dots, v_r$ - ортонормированная система и $f(u_i) = z_i = \sigma_iv_i\ (i = 1, \dots, r)$, $f(u_i) = 0,\ (i = r + 1, \dots, m)$

Теперь докажем единственность чисел $\sigma_1, \dots, \sigma_m$. Рассмотрим матрицу отображения $F$ в базисах $u_i$ и $v_i$. $[f] \begin{pmatrix}\sigma_1 ^ 2  & 0 & \dots & 0 & 0\\ 0 & \sigma_2 ^ 2 & \dots & 0 & 0\\ \dots & \dots & \dots & \dots &  \\ 0 & 0 & \dots & \sigma_r ^ 2 & 0  \\ \dots & \dots & \dots & \dots  & \dots \\ 0 & 0 & 0 &0 & 0\end{pmatrix}$, $[f^*] = \begin{pmatrix}\sigma_1 ^ 2  & 0 & \dots & 0 & 0\\ 0 & \sigma_2 ^ 2 & \dots & 0 & 0\\ \dots & \dots & \dots & \dots &  \\ 0 & 0 & \dots & \sigma_r ^ 2 & 0  \\ \dots & \dots & \dots & \dots  & \dots \\ 0 & 0 & 0 &0 & 0\end{pmatrix}$. При этом первая матрица размера $m\times n$, а вторая - $n\times m$. Поэтому $[f\circ f^*] = \begin{pmatrix}\sigma_1 ^ 2  & 0 & \dots & 0 & 0\\ 0 & \sigma_2 ^ 2 & \dots & 0 & 0\\ \dots & \dots & \dots & \dots &  \\ 0 & 0 & \dots & \sigma_r ^ 2 & 0  \\ \dots & \dots & \dots & \dots  & \dots \\ 0 & 0 & 0 &0 & 0\end{pmatrix}$ - матрица $n\times n$.  При этом $\sigma_1 ^ 2, \dots, \sigma_r ^ 2$. Осталось заметить, что собственные числа определяются однозначно, так как мы по условию брали их положительными. При этом $\sigma_1, \dots, \sigma_r$ называются ==сингулярными числами==. Для определённости можно упорядочить их по убыванию.

### Теорема о свойствах наибольшего сингулярного числа.
**Теорема**
Пусть $L_1, L_2$ - конечномерные пространства со скалярным произведением. Пусть $f: L_1 \mapsto L_2$ - ненулевое отображение. Тогда $\forall x \in L_1: |f(x)| \leq \sigma_1|x$, где $\sigma_1$ - наибольшее сингулярное число.

**Доказательство**
Возьмём $\sigma_1 \geq \sigma_2 \geq \dots \geq \sigma_r$ - сингулярные числа. Тогда $u_1, u_2, \dots, u_m$ - соответствующий ОНБ из собственных векторов. Пусть $x = a_1u_1 + \dots + a_m u_m$. Тогда $f(x) = a_1f(u_1) + \dots + a_m f(u_m) = a_1\sigma_1 v_1 + \dots + a_r\sigma_r v_r =$ $= a_1\sigma_1 v_1 + \dots + a_r\sigma_r v_r$. Так как $v_1, \dots, v_r$ - ортонормированная система, то $|f(x)|^2 = (f(x), f(x)) = (a_1\sigma_1 v_1 + \dots + a_r\sigma_r v_r) =$
Ребятки, записать не успел, наблюдайте скриншот Расина.![](attachments/Pasted%20image%2020230410163134.png)
![](attachments/Pasted%20image%2020230410163424.png)

**Следствие**
Наибольшее сингулярное значение $\sigma$ это $\max\limits_{|x| = 1} |f(x)$.

### ??Что??
***

%%не очень понял, о чём конкретно говорит Расин%%
В соответствующих ОНБ матрица оператора $f$ имеет вид $[f] \begin{pmatrix}\sigma_1 ^ 2  & 0 & \dots & 0 & 0\\ 0 & \sigma_2 ^ 2 & \dots & 0 & 0\\ \dots & \dots & \dots & \dots &  \\ 0 & 0 & \dots & \sigma_r ^ 2 & 0  \\ \dots & \dots & \dots & \dots  & \dots \\ 0 & 0 & 0 &0 & 0\end{pmatrix}$. Продолжение с этого момента: ![](attachments/Pasted%20image%2020230410164457.png)
![](attachments/Pasted%20image%2020230410164950.png)

### Теорема о сингулярном разложении матрицы
**Теорема**
1) Пусть $A$ - матрица над $\mathbb C$. Тогда существуют положительные числа $\sigma_1 \geq \dots \geq \sigma_r > 0$ и такие *унитарные матрицы* $U$ и $V$ такие, что $A = V \begin{pmatrix}\sigma_1 ^ 2  & 0 & \dots & 0 & 0\\ 0 & \sigma_2 ^ 2 & \dots & 0 & 0\\ \dots & \dots & \dots & \dots &  \\ 0 & 0 & \dots & \sigma_r ^ 2 & 0  \\ \dots & \dots & \dots & \dots  & \dots \\ 0 & 0 & 0 &0 & 0\end{pmatrix} U$
2) Пусть $A$ - матрица над $\mathbb C$. Тогда существуют положительные числа $\sigma_1 \geq \dots \geq \sigma_r > 0$ и такие *ортогональные матрицы* $U$ и $V$ такие, что $A = V \begin{pmatrix}\sigma_1 ^ 2  & 0 & \dots & 0 & 0\\ 0 & \sigma_2 ^ 2 & \dots & 0 & 0\\ \dots & \dots & \dots & \dots &  \\ 0 & 0 & \dots & \sigma_r ^ 2 & 0  \\ \dots & \dots & \dots & \dots  & \dots \\ 0 & 0 & 0 &0 & 0\end{pmatrix} U$

**Доказательство**
Следует из предыдущего.

## Псевдообратное отображение

> [!question] Что это было?..
> Пусть $f: L_1\mapsto L_2$ - линейное отображение в пространстве со скалярным произведением. Пусть $m = \dim L_1, n = \dim L_2$. По теореме о сингулярном разложении существуют ОНБ $u_1, \dots, u_m$ в $L_1$ и $v_1, \dots, v_n$ в $L_2$. При этом для некоторого $r$ для всех $i \in 1,\dots, r$ $f(u_i) = \sigma_i v_i$ и $f(u_i) = 0$, если $i = r+1, \dots, m$. $\sigma_i$ - сингулярные числа, $\sigma_i > 0, 1 \leq i \leq r$. $f(u_i) = \sigma_i v_i,\ i = 1\dots r$. Рассмотрим для $L_2$ отображение $g(v_i) = \dfrac 1 {\sigma_i} u_i$, при $i = 1,\dots, r$. Рассмотрим отображение $f^+(y) = \begin{cases} g(y): y \in <v_1, \dots, v_r>\\ 0, y \in <v_{r+1}, \dots, v_n\end{cases}$


> [!abstract] Псевдообратное отображение
> Отображение $f^+(y): L_2 \mapsto L_1$ (см. выше) называется ==псевдообратным== к отображению $f$.

## Приложения сингулярного разложения
### Формулировка задачи
![](attachments/Pasted%20image%2020230418131608.png)
Пусть даны точки $M_1, \dots, M_n$. Нужно провести прямую таким образом, чтобы сумма расстояний от точек до этой прямой была наименьшей.


> [!abstract] 
> Пусть дано линейное пространство $L$, $M$ - его подпространство, $r$ - некоторый вектор. Множество векторов вида $r + M = \Pr + u : u\in M\}$ называется ==линейным многообразием== в $L$. При этом $M$ называется ==направляющим подпространством== для многообразия $r + M$. %%Держу в курсе, это было в прошлом семе%%

### Лемма о линейных многообразиях
**Лемма**
$r + M = s + M \iff r - s \in M$.

**Доказательство**
$\implies$. %%как сказал Расин: Ну, туда. Туда ваще легко доказать.%% $u \in r + M,\ s + M$. Тогда $u = r + m_1 = s + m_2$. Таким образом, $r - s \in M$
$\impliedby$. Расин сказал доказать самосотятельно.

### Теорема
**Теорема**
Предположим, что для любых векторов $x_1, \dots, x_n$ линейное многообразие $r + M$ имеет размерность $k$ и таково, что для любого многообразия $r' + M'$ размерности не более $k$ выполняется неравенство $\sum\limits_{i = 1}^n(\,d(x_i, r + M))^2 \leq \sum\limits_{i = 1}^n(\,d(x_i, r' + M'))^2$. Тогда $r + M = \dfrac {x_1 + x_2 + \dots + x_n}{n} + M$, <font style="color:#A6E3A1">где $\,d(x_i, r' + M')$ - длина ортогональное проекции вектора $x_i - r'$ на подпространство $M$.</font>

**Ljrfpftkmcndj**
Рассмотрим $s = \dfrac{x_1 + x_2 + \dots + x_n}{n}$. Пусть $w_i = x_i - s$ (ортогональная составляющая вектора $x_i - s$)
$\sum\limits_{i = 1}^n (x_i - s) = (\bar x_1 + \dots + \bar x_n - n\bar s) = \bar x_1 + \dots + \bar x_n - (\bar x_1 + \dots + \bar x_n) = 0$
В частности $w_1 + \dots + w_n = 0$, и, следовательно $w_n = -w_1 - \dots - w_{n-1}$

Пусть $r$ - вектор как в условии теоремы. Рассмотрим ортогональную составляющую $t = s - r$ на подпространство $M$. $x_i - r = (x_i - s) + (s - r) = w_i + t$. $\sum\limits_{i=1}^n (\,d(x_i, r + M))^2 = \sum\limits_{i = 1}^n (\,d(x_i - r, M))^2 =$ $=\sum\limits_{i=1}^n |w_i + t|^2 = \sum\limits_{i = 1}^{n - 1} |w_i + t|^2 + |w_n + t|^2 =$ $= \sum\limits_{i = 1}^{n - 1} |w_i + t|^2 + |-w_1 - \dots - w_{n - 1} + t|^2 =$ $= \sum\limits_{i = 1}^{n - 1} |w_i + t|^2 + |t - \sum\limits_{i=1}^{n - 1} w_i|^2 =$ $= \sum\limits_{i=1}^{n-1}\left ( (w_i, w_i) + (w_i, t) + (t, w_i) + (t_t)\right) + (t, t) -$$-\left(t,\sum\limits_{i = 1}^{n - 1} w_i\right)- \left(\sum\limits_{i = 1}^{n - 1} w_i,\ t \right) + \left(\sum\limits_{i = 1}^{n - 1} w_i,\sum\limits_{i = 1}^{n - 1} w_i \right) =$ $=\sum\limits_{i = 1}^{n - 1} |w_i|^2 + \left( \sum\limits_{i = 1}^{n - 1} w_i, t \right)+ \left ( t, \sum\limits_{i = 1}^{n - 1} w_i \right)+ ( n - 1)|t^2| + |t^2| -$$- \left(t, \sum\limits_{i = 1}^{n-1} w_i\right) - \left(\sum\limits_{i = 1}^{n - 1} w_i, t\right)+ \left(\sum\limits_{i = 1}^{n - 1} w_i, \sum\limits_{i = 1}^{n - 1} w_i\right)=$$=\sum\limits_{i = 1}^{n - 1} |w_i|^2 + n|t^2| + (w_n, w_n) =$$= \sum\limits_{i = 1}^{n - 1} |w_i|^2 + n|t^2| + |w_n|^2 = \sum\limits_{i = 1}^b |w_i|^2 + n|t^2|$


Поскольку у ортогональной составоябщей вектора $r$ длина наименьшая  по предположению, то
$$\sum\limits_{i = 1}^n |w_i|^2 + n|t^2| \geq \sum\limits\limits_{i = 1}^n |w_i|^2=$$$$= \sum\limits+{i = 1}^n \,d(x_i, s + M)^2 \geq \sum\limits \,d(x_i, r+ M)^2$$
Поскольку изначально раскладывалась правая часть неравенства и она совпадает с левой, то
$$\sum\limits_{i = 1}^n |w_i|^2 + n|t^2| = \sum\limits_{i = 1}^n |w_i| ^ 2$$


> [!ERROR] УРА
> ЭТА ШЛЯПА КОНЧИЛАСЬ
> ---


