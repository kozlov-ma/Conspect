# Определители
## Перестановки и подстановки
### Перестановки и число инверсий
> [!abstract] Перестановка
> ==Перестановкой== множества числе $1, 2, \dots, n$ называется любая последовательность длины $n$, в которой каждое число от $1$ до $n$ входит в точности один раз.

> [!abstract] Число инверсий
> ==Числом инверсий== перестановки называется количество пар вида $(i, j),\ i < j$ таких, что в перестановке $g$ элемент $j$ имеет меньший номер, чем элемент $i$.

**Пример:** в перестановке $(1, 2, 4, 3)$ одна инверсия, а в перестановке $(4, 2, 1, 3)$ - $4$ инверсии.

> [!abstract] Чётная перестановка
> Перестановка называется ==чётной==, если в ней чётное число инверсий, и нечётной, если в ней нечётное число инверсий.

### Теорема о чётности перестановки
**Теорема**
Пусть $g$ - перестановка. Тогда при перестановке любой пары элементов чётность подстановки меняется.

**Доказательство**
Пусть $g$ имеет $m$ инверсий. 
1) Рассмотрим случай, когда переставляются соседние элементы. $g = (i_1, \dots, i_k, i_{k+1}, \dots, i_n)$. Если $i_k < i_{k+1}$, то образуется ровно одна новая инверсия.
2) $(i_1, \dots, i_k, i_{k+1}, \dots, i_{s - 1}, i_s, \dots, i_n)$. Мы переставляем $i_k$ и $i_s$.
   - $(i_1, \dots, i_k, i_{k+1},, i_{k+2} \dots, i_k, i_s, \dots,i_n)$. Мы сделаем $s - 1 - k$ перестановок соседних элементов, тогда чётность поменяется $ s - 1 - k$ раз.
   - Просто переставляем $i_k$ и $i_s$. $(i_1, \dots, i_{k+1}, \dots, i_{k+2}, \dots, i_s, i_k, \dots, i_n)$. Чётность меняется на $1$.
   - Ведём $i_s$ назад на то место, где сейчас находится $i_{k+1}$, на которой вначале стоял $i_k$. Снова после $s - 1 - k$ перестановок чётность поменяется.
Осталось заметить, что чётность поменялась нечётное количество раз.



### Подстановки

> [!abstract] Подстановка
> ==Подстановка== на множестве чисел от $1$ до $n$ - биекция на множестве $\left \{ 1, 2, \dots, n\right \}$. Подстановку можно записать в следующем виде: $\begin{pmatrix} 1 & 2 & \dots & n \\ i_1 & i_2 & \dots & i_n \end{pmatrix}$. Верхний ряд не обязательно записывать по порядку.

> [!note] 
> Подстановка состоит из двух перестановок (из перестановки в верхнем ряду и перестановки в нижнем ряду).

> [!abstract] Число инверсий
> ==Числом инверсий== подстановки называется сумма чисел инверсии её перестановок.

> [!abstract] Чётность подстановки
> Подстановка называется чётной, если её число инверсий чётно.

### Теорема о чётности подстановок
**Теорема**
1) Любая подстановка может быть представлена в  каноническом виде
2) Чётность подстановки не зависит от упорядочения верхнего ряда

**Доказательство**
1) Просто записываем подстановку по порядку. Очевидно, что ей соответствует то же самое отображение
2) $\begin{pmatrix} a_1 & \dots & a_i & \dots & a_k &\dots & a_n \\ b_1 & \dots & b_i & \dots & b_k &\dots & b_n\end{pmatrix}$. Переставим в этой подстановке $i$-й и $k$-й элементы. При этом сама подстановка не изменится. При этом по предыдущей теореме чётность не изменилась, т.к. одновременно изменились чётности верхнего и нижнего ряда.

### Единичные и обратные подстановки
> [!abstract] Единичная подстановка
> Подстановка вида $\begin{pmatrix} 1 & 2 & \dots & n \\ 1 & 2 & \dots & n\end{pmatrix}$ называется ==единичной==. 

Для каждой подстановки $g = \begin{pmatrix} 1 & 2 & \dots & n \\ i_1 & i_2 & \dots & i_n\end{pmatrix}$ есть обратная $g^{-1} = \begin{pmatrix} i_1 & i_2 & \dots & i_n \\ 1 & 2 & \dots & n\end{pmatrix}$ 


> [!NOTE] Чётность обратной подстановки
> Обратная подстановка имеет такую же чётность, как исходная.


## Определители
### Определители малых порядков
$$A = \begin{vmatrix} a_{11} & a_{12} \\ a_{21} & a_{22}\end{vmatrix} = a_{11}a_{22} - a_{12}a_{21}$$
$$A = \begin{vmatrix} a_{11} & a_{12} & a_{13} \\ a_{21} & a_{22} & a_{23} \\ a_{31} & a_{32} & a_{33} \end{vmatrix} = a_{11} \begin{vmatrix} a_{22} & a_{23} \\ a_{32} & a_{33} \end{vmatrix} - a_{12} \begin{vmatrix} a_{21} & a_{23} \\ a_{31} & a_{33} \end{vmatrix} + a_{31} \begin{vmatrix} a_{21} & a_{22} \\ a_{31} & a_{32} \end{vmatrix} = $$
$$= a_{11}a_{22}a_{33} - a_{11}a_{23}a_{32} - a_{12}a_{21}a_{33} + a_{12}a_{23}a_{31} + a_{13}a_{21}a_{32} - a_{13}a_{22}a_{31}$$

1) В каждом слагаемом нет элеметнов, лежащих в одной строке или столбце
2) Каждому слагаемому соответствует подстановка $\begin{pmatrix} 1 & 2 & 3 \\ i_1 & i_2 & i_3\end{pmatrix}$, где верхний ряд - номера столбцов, нижний ряд - номера строк соответствуюшщих элементов.
### Определитель в общем случае
Пусть $S_n$ - множество всех подстановок $\left \{1,2,\dots, n\right \}$. Тогда $|S_n| = n!$

> [!abstract] Определитель
> Пусть $a$ - матрица $n\times n$: $\begin{pmatrix} a_{11} & a_{12} & \dots & a_{1n} \\ a_{21} & a_{22} & \dots & a_{2n} \\ \dots & \dots & \dots & \dots \\ a_{n1} & a_{n2} & \dots & a_{nn} \end{pmatrix}$. ==Определителем== такой матрицы называется число $|A| = \det A = \sum\limits_{g\in S_n} (-1)^g a_{1g(1)}a_{2g(2)}\dots a_{ng(n)}$. Под $g$ в $(-1)^g$ имеется в виду чётность подстановки $g$.

### Транспонирование матриц
> [!abstract] Транспонированная матрица
> Матрица $A^T$, полученная из $A$ заменой строк на столбцы и столбцов на строки, или симметрией относитеьно главной диагонали $A$, называется ==транспонированной== к $A$.

### Теорема об определителе транспонированной матрицы
**Теорема**
$|A| = |A^T|$

**Доказательство**
$$|A| = \sum\limits_{g\in S_n} (-1)^g a_{1g(1)}a_{2g(2)}\dots a_{ng(n)} \quad (*)$$. Поскольку строки транспонированной матрицы меняются на столбцы (можно сказать, что местами меняются верхняя и нижняя строка каждой перестановки), то $$|A^T| = \sum\limits_{g\in S_n} (-1)^{g^{-1}} a_{g(1)1}a_{g(2)2}\dots a_{g(n)n}\quad (**)$$.
Заметим, что в $(*)$ и в $(**)$ одинаковоке количество слагаемых, и что для каждой подстановки $g$ в $|A|$ эта подстановка есть и в $|A^T|$. Слагаемому $a_{1g(1)}a_{2g(2)}\dots a_{ng(n)}$ соответствует слагаемое $a_{g(1)1}a_{g(2)2}\dots a_{g(n)n}$ (в транспонированной матрице). То есть слагаемые не изменились, то задаются обратными подстановками. Но для обратной подстановки чётность сохраняется, поэтому знаки слагаемых сохраняются.

### Теоремы о свойствах определителя

> [!abstract] Минор
> ==Минор== матрицы $M_{ij}$ для элемента $a_{ij$ получается вычёркиванием $i$-й строки и $j$-го столбца из $a_{ij}$


> [!abstract] Алгебраическое дополнение
> Алгебраическим дополнением элемента $a_{ij}$ называется число $A_{ij} = (-1)^{i+j} |M_{ij}|$


**Теорема**
1) $|A| = |A^T|$
2) При умножении строки определителя на число, весь определитель умножается на это число
3) Если определитель содержит нулевую строку, то он равен нулю.
4) Если в определителе поменять местами две строки, то он поменяет знак.
5) Если в определителе есть одинаковые строки, то он равен нулю.
6) Если в определите есть пропорциональные строки, то он равен нулю.
7) Разложение определителя в сумму определителей. $\begin{vmatrix} a_{11} & \dots & a_{1k-1} & b_{1k} + c_{1k} & a_{1k + 1} & \dots & a_{tn} \\ \dots & \dots & \dots &  \dots & \dots & \dots & \dots \\ a_{m1} & \dots & a_{mk-1} & b_{mk} + c_{mk} & a_{mk + 1} & \dots & a_{tn}  \\ dots & \dots & \dots &  \dots & \dots & \dots & \dots \\ a_{n1} & \dots & a_{nk-1} & b_{nk} + c_{nk} & a_{nk + 1} & \dots & a_{nn} \end{vmatrix}$
8) Если к одной строке определителя прибавить другую строку, умноженную на число, то значение определителя не изменится.
9) Разложение по строке: $|A| = a_{k1}A_{k1} + a_{k2}A_{k2} + \dots + a_{kn}A_{kn}$
10) Сумма произведений алегбраических дополнений элементов одной строки на алгебраические дополнения другой строки равна нулю
11) Определитель треугольной матрицы равен произведению диагональных элементов
12) Любой определитель можно вычислить приведением к треугольному виду.

Все свойства определителя, справедливые для строк, остаются справедливыми для столбцов, и наоборот.

**Доказательство**
2) $\begin{vmatrix} a_{11} & a_{12} & \dots & a_{1n} \\ a_{21} & a_{22} & \dots & a_{2n} \\ \dots & \dots & \dots & \dots \\ ta_{k1} & ta_{k2} & \dots & t_a{kn} \\ \dots & \dots & \dots & \dots \\ a_{n1} & a_{n2} & \dots & a_{nn} \end{vmatrix} = \sum\limits_{g\in S_n} (-1)^g a_{1g(1)}\dots t(a_{kg(k)}) \dots a_{ng(n)}$. По свойству определителя каждое слагаемое умножится на $t$, поэтому значение определителя уможится на $t$
3) Следует из 2).
4) $\begin{vmatrix} a_{11} & a_{12} & \dots & a_{1n} \\ a_{21} & a_{22} & \dots & a_{2n} \\ \dots & \dots & \dots & \dots \\ ta_{k1} & ta_{k2} & \dots & t_a{kn} \\ \dots & \dots & \dots & \dots \\ a_{m1} & a_{m2} & \dots & a_{mn} \\ \dots & \dots & \dots & \dots \\ a_{n1} & a_{n2} & \dots & a_{nn} \end{vmatrix} = \sum\limits_{g\in S_n} (-1)^g a_{1g(1)}\dots t(a_{kg(k)}) \dots a_{ng(n)}$. Если переставить местами строки, в каждом слагаемом поменяется чётность подстановки, то есть слагаемому будет соответствовать оно же со знаком $-$.
5) Следует из свойства 4, т.к. если переставить эти строки местами, то он должен поменять знак, но сам определитель не изменится, поэтому он равен нулю. 
6) Из свойств 2) и 5)
7) $$\begin{vmatrix} a_{11} & \dots & a_{1k-1} & b_{1k} + c_{1k} & a_{1k + 1} & \dots & a_{tn} \\ \dots & \dots & \dots &  \dots & \dots & \dots & \dots \\ a_{m1} & \dots & a_{mk-1} & b_{mk} + c_{mk} & a_{mk + 1} & \dots & a_{tn}  \\ dots & \dots & \dots &  \dots & \dots & \dots & \dots \\ a_{n1} & \dots & a_{nk-1} & b_{nk} + c_{nk} & a_{nk + 1} & \dots & a_{nn} \end{vmatrix} = $$ $$= \sum\limits_{g\in S_n} (-1)^g a_{1g(1)}(b_{g(k)k} + c_{g(k)k})\dots a_{g(n)n} + $$ %%КАВО%%
8) Добавим к $m$-й строке $k$-ю, умноженную на $t$ $$\begin{vmatrix} a_{11} & a_{12} & \dots & a_{1n} \\ \dots & \dots & \dots & \dots \\ a_{k1} & a_{k2} & \dots & a_{kn} \\ \dots & \dots & \dots & \dots \\ a_{m1} & a_{m2} & \dots & a_{mn} \\ \dots & \dots & \dots & \dots \\ a_{n1} & a_{n2} & \dots & a_{nn}\end{vmatrix} = \begin{vmatrix} a_{11} & a_{12} & \dots & a_{1n} \\ \dots & \dots & \dots & \dots \\ a_{k1} & a_{k2} & \dots & a_{kn} \\ \dots & \dots & \dots & \dots \\ a_{m1} + ta_{k1} & a_{m2} + ta_{k2} & \dots & a_{mn} + ta_{kn} \\ \dots & \dots & \dots & \dots \\ a_{n1} & a_{n2} & \dots & a_{nn}\end{vmatrix} = $$
   $$= \begin{vmatrix} a_{11} & a_{12} & \dots & a_{1n} \\ \dots & \dots & \dots & \dots \\ a_{k1} & a_{k2} & \dots & a_{kn} \\ \dots & \dots & \dots & \dots \\ a_{m1} & a_{m2} & \dots & a_{mn} \\ \dots & \dots & \dots & \dots \\ a_{n1} & a_{n2} & \dots & a_{nn}\end{vmatrix} + \begin{vmatrix} a_{11} & a_{12} & \dots & a_{1n} \\ \dots & \dots & \dots & \dots \\ a_{k1} & a_{k2} & \dots & a_{kn} \\ \dots & \dots & \dots & \dots \\ ta_{k1} &  ta_{k2} & \dots & ta_{kn} \\ \dots & \dots & \dots & \dots \\ a_{n1} & a_{n2} & \dots & a_{nn}\end{vmatrix}$$
   Во втором определителе имеем пропорциональные строки, т.е. он равен нулю, т.е. исходный определитель не изменился.
9) Достаточно доказать для разложения по первой строке. Рассмотрим определение определителя. $$\begin{vmatrix} a_{11} & a_{12} & \dots & a_{1n} \\ a_{21} & a_{22} & \dots & a_{2n} \\ \dots & \dots & \dots & \dots \\ a_{n1} & a_{n2} & \dots & a_{nn} \\  \end{vmatrix}= \sum\limits_{g\in S_n} (-1)^g a_{1g(1)}a_{2g(2)}\dots a_{ng(n)} = a_{11}R_1 + a_{12}R_2 + \dots + a_{1n}R_n$$. $R_i$ - все слагаемые, куда входит $a_{1i}$. Покажем, что $R_i = (-1)^{1 + i}M_{1i}$. Очевидно, что слагаемые в $R_i$ и $(-1)^{1 + i} M_{1i}$ одни и те же, поскольку при раскрытии определителя мы выбираем по одному слагаемому в каждой строке и в каждом столбце. Осталось показать, что слагаемые входят с правильным знаком. Возьмём элемент $a_{1k}a_{2g(2)}\dots a_{ng(n)}$. Ему соответствует подстановка $g' = \begin{pmatrix} 2 & \dots & n \\ g(2) & \dots & g(n)\end{pmatrix}$, где $g(i) \neq k$. Пусть чётность этой подстановки равна $i(g')$. В $g$ $k$ стоит на первом месте и вносит дополнительно $kg'((k - 1))$, поэтому $i(g) = k -1 + i(g')$, поэтому каждому слагаемому из $M_{1k}a_{2g}\dots a{ng(n)}$ соответствует слагаемое $a_{1k}a_{2g(2)}\dots a_{ng(n)}$, которое в $A$ различается на $(-1)^{k - 1} = (-1) = (-1)^{k+1}(i(g')\text{ - число инверсий для исходного слагаемого)}$. Поэтому все элементы из $M_{1k}$ нужно умножить на $(-1)^{k+1}$, из чего получается формула разложения по строке.
10) $a_{k1}A_{m1}+ a{k2}A_{m2} + \dots + a_{kn}A_{mn} =$ В алгебраических дополнениях $A_{ms}$ нет $m$-й строки, т.е. получить такую сумму - то жке самое, что взять определитель матрицы, у которой $m$-я строка совпадает с $k$-й и разложить по $m$-й строке.
11) $\begin{vmatrix}a_{11} & a{12} & \dots & a_{1n} \\ 0 & a_{22} & \dots & a_{2n} \\ \dots & \dots & \dots & \dots \\ 0 & 0 & \dots & a_{nn}\end{vmatrix}$. Необходимо разложить определитель по первому столбцу. Получаем $a_{11}$ на такой же определитель, кроме первой строки. Повторим этот шаг $n$ раз. Очевидно, что определитель разложится в произведение диагональных элементов.
12) Следствие св-в **8)** и **11)**
## Полураспавшаяся матрица

> [!abstract] Полураспавшаяся матрица
> Матрица вида $\begin{pmatrix} A & N \\ O & B\end{pmatrix}$, где матрицы $A$ и $B$ - квадратные, $O$ - нулевая матрица называется ==полураспавшейся==.

### Теорема об определителе полураспавшейся матрицы
**Теорема**
$$\begin{vmatrix} A & N \\ O & B\end{vmatrix} = |A|\cdot |B|$$

**Доказательство**
Докажем индукцией по порядку матрицы $A$
1) $p = 1$. $\begin{vmatrix} a_{11} & N \\ O & B\end{vmatrix}$. Таким образом, $O$ - столбец из нулей. Раскладываем матрицу $M$ по первому столбцу и получаем $|M| = a_{11}|B| = |A|\cdot |B|$
2) Пусть доказано для матриц порядка меньшего, чем $p$: $$\begin{vmatrix} a_{11} & a_{12} & \dots & a_{1p} & ** & \dots & ** \\ \dots & \dots & \dots & \dots & \dots & \dots & \dots \\ a_{p1} & a_{p2} & \dots & a_{pp} & ** & \dots & ** \\ 0 & 0 & \dots & 0 & b_{11} & \dots & b_{1s} \\ \dots & \dots & \dots & \dots & \dots & \dots & \dots \\ 0 & 0 & \dots & 0 & b_{s1} & \dots & b_{ss}\end{vmatrix} = \left\{ \text{разложим по первому столбцу}\right \} = $$
   $$= a_{11}(-1)^{1 + 1} \begin{vmatrix} M_{11} & * \\ O & B\end{vmatrix} + \dots + a_{k1}(-1)^{k + 1} \begin{vmatrix} M_{1k} & ** \\ O & B\end{vmatrix} + a_{p1}(-1)^{p + 1} \begin{vmatrix} M_{p1} & * \\ O & B\end{vmatrix} = $$
   $$= |A|\cdot |B|$$
### Теорема об определителе прозведения матриц
**Теорема**
Если $A, B$ - квадратные матрицы размера $n\times n$, то $|AB| = |A|\cdot |B|$

**Доказательство**
Построим специальную матрицу $D = \begin{vmatrix}A & O \\ -E & B\end{vmatrix}$, где $-E$ - единичная матрица размера $n\times n$, у которой на главной диагонали стоят $-1$, а остальные элементы - нули. Очевидно, что $D$ - транспонированная к полураспавшейся, и её определитель $|D| = |A|\cdot |B|$.
$$\begin{vmatrix} a_{11} & \dots & 0 & \dots & 0 \\ \dots & \dots & \dots & \dots & \dots \\ a_{n1} & \dots & a_{2n} & 0 & \dots & 0 \\ -1 & \dots & 0 & b_{11} & \dots & b_{1n}  \\ \dots & \dots & \dots & \dots & \dots  \\ 0 & \dots & -1 & b_{n1} & \dots & b_{nn}\end{vmatrix}$$
Начнём обнулять позиции, где есть элементы $b_{ij}$. Далее к $n+1$-му столбцу прибавим второй столбец, умноженный на $b_{21}$. Далее к $n+1$-му столбцу прибавим $n$-ый, умноженный на $b_{n1}$. Таким образом, в первых $n$ строках получившейся матрицы расположен первый столбец матрицы $A\cdot B$. Проделывая аналогичные действия со $n+2$-м столбцом, далее  - с $2n$ столбцом, получим следующую матрицу: $\begin{vmatrix}A & C \\ -E & 0\end{vmatrix}$. Переставим $n+1$-й столбец с $1$-м, $n+2$-й - со $2$-м, и так далее. Получим определитель следующего вида: $(-1)^n\begin{vmatrix}C & A \\ O & -E\end{vmatrix}$
***
##  Обратная матрица и система линейных уравнений

> [!abstract] Обратная матрица
> Матрица $B$ называется ==обратной== к матрице $A$, если $AB = BA = E$

### Теорема: критерий обратимости квадратной матрицы
**Теорема**
Квадратная матрица обратима $\iff$ её определитель отличен от нуля

**Доказательство**
1. Пусть $A$ - обратима. Посчитаем $$\det AA^{-1} = \det A \cdot \det A^{-1} = 1  \implies $$$$ \implies \det A \neq 0,\ \det A^{-1} =(\det A)^{-1}$$
2. Умножим присоединённую к $A$ матрицу $(A^\#)^T$ - матрицу алгебраических дополнений к каждому элементу матрицы $A$ на матрицу $A$, получится матрица, на главной диагонали которой стоят $\det A$ . Рассмотрим матрицу, полученную из матрицы $A$ заменой второй строки на первую. Её определитель будет равен нулю Продолжим этот шаг и найдём матрицу $A(A^\#)^T = \begin{pmatrix}\det A & 0 & \dots & 0 \\ 0 & \det A & \dots & 0 \\ \dots  & \dots & \dots & \dots \\ 0 & 0 & \dots & \det A \end{pmatrix} = \det A \cdot E$
   $$A^{-1} = \dfrac {1}{\det A}(A^\#)^T$$
   $(A^\#)^TA$ - аналогично, т.к. вместо разложения по строке будет разложение по столбцу.

### Крамерова система линейных уравнений

> [!abstract] Крамерова система линейных уравнений
> $\begin{cases} a_{11}x_1 + a_{12}x_2 + \dots + a_{1n}x_n = b_1 \\ a_{21} x_1 + a_{22} x_2 + \dots + a_{2n}x_n = b_2 \\ \dots \\ a_{m1}x_1 + a_{m2}x_2 + \dots + a_{mn}x_n = b_m\end{cases}$ 
> Эта система называется ==Крамеровой==, если $m = n$ и $\det A = 0$, где $A$ - главная матрица системы.

### Теорема о единственности решения Крамеровой системы
**Теорема**
Крамерова система уравнений имеет решение, и притом только одно.

**Доказательство**
Поскольку $\det A \neq 0$, то $\exists A^{-1}$. $$Ax = A(A^{-1} b) = (AA^{-1})b = Eb = b$$
Пусть $x = A^{-1}b$
Предположим, что решение не единственно, то есть $Ay = b$. Тогда $A^{-1}(A_y) = A^{-1}b = (A^{-1}A)y = Ey = y$.

### Формула Крамера


 $$A^{-1}b = \dfrac 1 {\det A}(A^\#)^T b = $$$$ =\dfrac 1 {\det A}\begin{pmatrix}A_{11} & A_{21} & \dots & A_{n1} \\ A_{12}  & A_{22} & \dots  & A_{n2} \\ \dots & \dots & \dots & \dots \\ A_{1n} & A_{2n} & \dots & A_{nn} \end{pmatrix}\begin{pmatrix} b_1 \\ \dots \\ \dots \\ b_n\end{pmatrix} = $$$$= \dfrac 1 {\det A}\begin{pmatrix}\det A_1  \\  \det A_2  \\  \dots  \\  \det A_n\end{pmatrix}$$
 где $\det \begin{pmatrix} b_1 & a_{12} & \dots & a_{1n} \\ b_2 & a_{22} & \dots & a_{2n} \\ \dots & \dots & \dots & \dots \\ b_1 & a_{n1} & \dots & a_{nn}\end{pmatrix}$

> [!tip]
> Таким образом, формула $x =\dfrac{\det A_i}{\det A}$ называется ==формулой Крамера==.

### Общее решение систем линейных уравнений

> [!abstract] Минор
> Выберем в матрице $k$ строк и $k$ столбцов. Возьмём элементы, которые стоят на пересечении этих строк и столбцов. Определитель, стоящий на пересечении этих $k$ строк и $k$ столбцов называется ==минором== $k$-го порядка.


> [!abstract] Минорный ранг матрицы
> ==Рангом матрицы по минорам== называется наивысший порядок отличных от нуля миноров.

### Теорема: ранг по минорам совпадает с рангом матрицы
**Доказательство**
$$A = \begin{pmatrix} a_{11} & \dots & a_{1j} & \dots & a_{1k} & \dots & a_{1n} & \dots & \dots & \dots & \dots & \dots & \dots & \dots  \\ a_{ & }\end{pmatrix}$$ \\ %%Гейн пишет непонятно%%

> [!TODO] Дайте
> Пацаны зашлите пожалуйста теоремку \\  \


> [!abstract] Общее решение системы
> Оставим в левой части только переменные $x_1, \dots, x_k$, а остальные перенесём в правую часть. Тогда система примет вид $\begin{cases} a_{1j_1}x_{j_1} + a_{1j_2} + \dots + a_{1j_k}x_n = b_1 - a_{11}x_1 - \dots - a_{xadf}x_1 \\ \dots \\ a_{kj_1}x_{j_1} + a_{kj_2}x_{j_2} + \dots + a_{kj_k}x_k = b_k - \dots\end{cases}$. Левые переменные называются ==зависимыми==, а в правой части - ==свободными==. Тогда каждая зависимая переменная - линейная комбинация свободных. Множество всех решений этой системы называется её ==общим решением==.


> [!abstract] Фундаментальная система решений
> Общее решение однородной (базис) системы называется ==фундаментальной системой решений==. 

## Определитель Вандермонда

> [!abstract] 
> Пусть даны $$n$$ чисел: $x_1, x_2, \dots, x_n$. ==Определителем Вандермонда== называется определитель, в котором в $k$-й строке записаны степени числа $x_k$ от $0$ до $n - 1$.

### Теорема: определитель Вандермонда
**Теорема**
$W(x_1, \dots, x_n) = \begin{vmatrix} 1  & x_1 & x_1^2 & \dots & x_1^{n-1} \\ 1 & x_2 & x_2^2 & \dots & x_2^{n - 1}  \\ \dots & \dots & \dots & \dots & \dots \\ 1 & x_n & x_n^2 & \dots & x_n^{n-1}\end{vmatrix} = \Pi_{1\leq i < j \leq k}(x_j - x_i)$
**Доказательство**
Б.И. - $n = 1$, $W(x_1) = 1$. При $n = 2$: $W(x_1, x_2) = \begin{vmatrix}1 & x_1 \\ 1 & x_2\end{vmatrix} = x_2 - x_1$
Ш.И. Пусть для определителей порядка менее $n - 1$. Из каждого столбца вычтем предыдущий, умноженный на $x_1$$$W(x_1, \dots, x_n) = \begin{vmatrix} 1  & x_1 & x_1^2 & \dots & x_1^{n-1} \\ 1 & x_2 & x_2^2 & \dots & x_2^{n - 1}  \\ \dots & \dots & \dots & \dots & \dots \\ 1 & x_n & x_n^2 & \dots & x_n^{n-1}\end{vmatrix} = $$$$= \begin{vmatrix} 1  & 0 & 0 & \dots & 0 \\ 1 & x_2 - x_1& x_2^2 - x_2x_1& \dots & x_2^{n - 1} - x_1x_2^{n-2}  \\ \dots & \dots & \dots & \dots & \dots \\ 1 & x_n - x_1 & x_n^2 - x_nx_1& \dots & x_n^{n-1} - x_1x_n^{n - 2}\end{vmatrix}$$
Разложим этот определитель по первой строке:$$\begin{vmatrix}  x_2 - x_1& x_2^2 - x_2x_1& \dots & x_2^{n - 1} - x_1x_2^{n-2}  \\  \dots & \dots & \dots & \dots \\  x_n - x_1 & x_n^2 - x_nx_1& \dots & x_n^{n-1} - x_1x_n^{n - 2}\end{vmatrix} = $$$$= \begin{vmatrix}  x_2 - x_1& x_2(x_2 - x_1)& \dots & x_2^{n - 2}(x_2 - x_1)  \\  \dots & \dots & \dots & \dots \\  x_n - x_1 & x_n(x_n - x)_1& \dots & x_n^{n-2}(x_n - x_1)\end{vmatrix} =$$$$ = (x_2 - x_1)\dots(x_n - x_1) = \begin{vmatrix} 1  & x_2 & \dots & x_2^{n-2} \\ \dots & \dots & \dots & \dots &  \\ 1 & x_n & \dots & x_n^{n-2}\end{vmatrix} =$$
Что является определителем Вандермонда порядка $n -1$. Воспользуемся формулой: $$= (x_n - x_1)\cdot \dots(x_2 - x_1)W(x_1, \dots, x_{n - 1}) =$$$$= (x_n - x_1) \dots(x_2 - x_1)\Pi_{1\leq i < j \leq n - 1}(x_j - x_i) $$



# Многочлены
## Определение многочлена

> [!abstract] Многочлен
> ==Многочленом== над полем $F$ называется выражение вида $f(x) = a_n x^n + a_{n - 1} x ^ {n - 1} + ... + a_1 x + a_0$, где $a_i \in F$, а $x$ - переменная.

> [!abstract] Степень многочлена
> Наибольшее $n$ такое, что $a_n \neq 0$ называется ==степенью многочлена==. При этом степень нулевого многочлена по определению равна $-\infty$. Степень многочлена обозначается $\deg f$.


## Операции над многочленами
1. Сложение
2. Умножение на число
3. Умножение многочленов

> [!tip] Свойство умножения
> $\deg (f(x) \cdot g(x)) = \deg f(x) + \deg g(x)$

> [!NOTE] Множество многочленов над полем $F$
> Множество многочленов переменной $x$ над полем $F$ обозначается $F[x]$

> [!caution] Обратимые многочлены
> Для множества многочленов над полем $F$ обратимы являются только многочлены нулевой степени

### Замечание: $F[x]$ является коммутативным кольцом с 1
Доказательство: есть две операции, + и ⋅. Очевидно, что + - ассоциативно и коммутативно. Умножение также ассоциативно и коммутативно. При этом по сложению и по умножению есть нейтральные элементы.
> [!tip] $F[x]$ является коммутативным кольцом с $1$
> Доказательство: есть две операции, $+$ и $\cdot$. Очевидно, что $+$ - ассоциативно и коммутативно. Умножение также ассоциативно и коммутативно. При этом по сложению и по умножению есть нейтральные элементы.





## Ассоциированные многочлены
> [!abstract] Ассоциированные многочлены
> Многочлены $f(x)$ и $g(x)$ называются ==ассоциированными== $(f(x) \sim g(x))$, если $f(x) = cg(x)$, где $c$ = некоторое постоянное число (или многочлен степени 0). Они часто имеют схожие свойства.

> [!note] Все многочлены нулевой степени ассоциированы с e(x)=1

> [!example] Пример ассоциированных многочленов
> 
$2x^2+x+1 \sim x^2+\frac{1}{2}x+\frac{1}{2}$



## Отношение делимости на множестве многочленов

> [!abstract] Делимость многочленов
> Многочлен $f(x)$ ==делится== на многочлен $g(x)$, если существует многочлен $h(x)$ такой, что $f(x) = g(x) \cdot h(x)$. Обозначается $g(x)\ |\ f(x)$ или $f(x)\ \vdots\ g(x)$

> [!example] Пример делимости многочленов
> $f(x)=x^2-3x+2=(x-2)(x-1)$
> $(x-2)\ |\ f(x)$
> $(x-1)\ |\ f(x)$

### Свойства отношения делимости для многочленов

Пусть $f(x), g(x) \neq 0$
1. Рефлексивность $f(x)|f(x)$
2. Транзитивность $f(x)|g(x)$ и $g(x)|h(x) \implies f(x)|h(x)$

Антисимметричность отсутствует, из-за наличия ассоциированных многочленов.

Другие свойства:
1. Если $f(x)\ | \ g(x)$, то имеет место $f(x)\ | \ (g(x) \cdot h(x))$
2. Если $f(x)\ | \ g(x)$ и $f(x) \ | \ h(x)$, то $f(x)\ | \ (g(x) + h(x))$

### Теорема о делении с остатком

> [!summary] Теорема
> 
Пусть $F$ - поле и $f(x), g(x) \in F[x]$ и $g(x) \neq 0$. Тогда $\exists! \text{ } q(x), r(x) : f(x) = q(x) \cdot g(x) + r(x)$, при этом $\deg r(x) < \deg g(x)$. 
$q(x)$ - частное
$r(x)$ - остаток

**Доказательство**
$$f(x) = a_kx^k + \dots + a_0$$
$$g(x) = b_mx^m + \dots + b_0$$
1. Докажем существование. В случае $k < m$ $q(x) = 0$, а $r(x) = f(x)$. В случае $k \geq m$ докажем по индукции по $k - m$:
   1) База индукции: $k - m = 0$. Тогда $r(x) = f(x) - \dfrac {a_k}{b_k} g(x)$ и $q(x) = \dfrac {a_k}{b_k}$
   2) Шаг индукции: $k - m > 0$. Предположим, что теорема доказана для всех значений, меньших, чем $k - m$. Тогда возьмём $q(x) = \dfrac {a_k}{b_k} x ^ {k - m}$ и $h(x) = f(x) - \dfrac {a_k}{b_k} x^{k - m} g(x)$. Тогда $\deg h(x) < k$. Тогда для $h(x)$ воспользуемся предположением индукции. Тогда
       $$f(x) = h(x) + \dfrac {a_k}{b_k}x^{k - m} g(x) =$$$$= \dfrac {a_k}{b_m}x^{k - m}g(x) + q_1(x)g(x) + r_1(x) = $$$$= (\dfrac {a_k}{b_m} x^{k - m} + q_1(x))g(x) + r_1(x)$$
2. Единственность. Предположим, что есть два разложения: $f(x) = q_1(x) g(x) + r_1(x) = q_2(x) g(x) + r_2(x)$. Тогда $$q_1(x) g(x) + r_1(x) = q_2(x)g(x) + r_2(x)$$
   $$q_1(x)g(x) - q_2(x)g(x) = r_2(x) -r_1(x)$$
   $$(q_1(x) - q_2(x))g(x) = r_2(x) - r_1(x)) \quad * $$
   Если мы умножаем на $g(x) \neq 0$, то степень многочлена не уменьшается. Тогда если $q_1(x) \neq q_2(x)$, то в $(*)$ степени равных многочленов отличаются. Поэтому $(*)$ выполняется только если $q_1(x) = q_2(x) \implies r_1(x) = r_2(x)$.




### Наибольший общий делитель

> [!abstract] Наибольший общий делитель
> Пусть $f(x), g(x)$ - многочлены над $F$. Тогда многочлен $d(x)$ называется их ==наибольшим общим делителем==, если $f(x) = 0$ и $d(x) = 0$ или $f(x)\neq$ и $g(x)\neq 0$ и $\forall c(x): c(x)\ |\ f(x) \wedge c(x)\ |\ g(x)\quad c(x)\ | \ d(x)$

### Алгоритм Евклида поиска НОД
Пусть $f(x), g(x) \in F[x], g(x) \neq 0$ и $f(x) = q_1(x) g(x) + r_1(x), g(x) = q_2(x) r_1(x) + r_2(x)$.

Поделим с остатком $f(x)$ на $g(x)$. Пусть $r_1$ - остаток. Тогда поделим $g(x)$ на $r_1$ с остатком $r_2$. Теперь поделим $r_1$ на $r_2$ с остатком $r_3$, и так далее. Алгоритм продолжается, пока мы не получим нулевой остаток. Последний ненулевой остаток $r_k$ - и есть НОД $f(x)$ и $g(x)$.

То, что алгоритм завершится за конечное число шагов следует из того, что на каждом шаге степени остатков уменьшаются $\implies$ на каком-то шаге получится нулевой остаток.





### Теорема о наибольшем общем делителе
**Теорема**
Для любой пары $f(x), g(x) \in F[x]$, если $d(x)$ = $\text{НОД}(f(x), g(x))$ существуют многочлены $u(x)$ и $v(x)$ такие, что $f(x)u(x) + g(x)v(x) = d(x)$

**Доказательство**
$f(x) = r_{-1}(x)$
$g(x) = r_0(x)$

1. Случай $f(x) = g(x) = 0$. Тогда $d(x) = 0$ и $u(x), v(x)$ - любые
2. Случай $f(x) = 0,\ g(x)\neq 0$. Тогда $d(x) = g(x)$, $u(x)$ - любой, $v(x) = 1$
3. Случай $f(x) \neq 0,\ g(x) \neq 0$. Из равенств, которые возникают в алгоритме Евклида, можно получить рекуррентные формулы для $u(x)$ и $v(x)$.
   
   Покажем, что для любого остатка, возникающего в алгоритме Евклида, существуют многочлены $u_k(x)$ и $v_k(x)$ такие, что $r_k(x) = f(x)u_k(x) + g(x)v_k(x)$.
   
   По алгоритму Евклида:
   Пусть $f(x) = r_{-1}(x)$ и $g(x) = r_0(x)$
   $$f(x) = 1 \cdot f(x) + 0 \cdot g(x), u_{-1}(x) = 1 \implies v_{-1}(x) = 0$$
   $$g(x) = 0 \cdot f(x) + 1 \cdot g(x) \implies u_0(x) = 0, v_0(x) = 1$$
   $$r_1(x) = f(x) - q_1(x) g(x)$$
   $$r_1(x) = r_{-1}(x) - q_1(x)r_0(x) =$$
   $$= (u_{-1}(x)f(x) + v_{-1}(x)g(x)) + q_{1}(x)(u_0(x)f(x) + v_0(x) g(x)) = $$
   $$ = (u_{-1}(x) - q_1(x)u_0(x)) f(x) + (v_{-1}(x) - q_1(x) v_0(x))$$
   
   Если $r_{i - 1}(x) = u_{i - 1}(x) f(x) + v_{i - 1}(x) g(x)$, а $r_i(x) = u_i(x)f(x) + v_i(x)g(x)$, то $$r_{i+1}(x) = r_{i - 1}(x) - q_i(x)r_i(x) = $$
   $$= u_{i - 1}(x) f(x) + v_{i - 1}(x) g(x) - q_i(x)(u_i(x) f(x) + v_i(x) g(x)) =$$
   $$ = (u_{i-1}(x) - q_i(x) u_i(x))f(x) + (v_{i-1}(x) = q_i(x)v_i(x))v(x)$$
   
   Тогда $u_{i+1}(x) = u_{i-1}(x) - q_1(x)u_i(x)$ и $u_i+1(x) = v_{i-1}(x) - q_i(x)v_i(x)$
   
   Таким образом, мы видим, что для всех $i \geq 1$ мы имеем разложение $r_i(x) = u_i(x) f(x) + v_i(x) g(x)$. Итак, поскольку $d(x)$ является одним из остатков в алгоритме евклида, то на каком-то шаге мы найдём разложение $d(x) = u(x)f(x) + v(x) g(x)$




## Взаимно простые многочлены
> [!abstract] Взаимно простые многочлены
> Многочлены называются ==взаимно простыми==, если их наибольшим общим делителем является многочлен нулевой степени.

### Теорема: критерий взаимной простоты многочленов
**Теорема**
Многочлены $f(x)$ и $g(x)$ являются взаимно простыми $\iff \exists u(x), v(x) \in F[x]$ такие, что $f(x)u(x) + g(x)v(x) = 1$.

**Доказательство**
1. $\implies$ - очевидено, следует из предыдущей теоремы.
2. $\impliedby$. От противного. Пусть $d(x) = \text{НОД}(f(x),\ g(x))$ и $\deg(d(x)) \geq 1$. Тогда, поскольку $d(x)$ делит левую часть равенства, то $d(x)\ | \ 1$, но это невозможно, т.к. $\deg d(x) > 1$. Противоречие.



### Свойства взаимно простых многочленов
**Теорема**
1) Если $f(x)\ | \ h(x)$ и $g(x)\ | \ h(x)$, то $(f(x) g(x))\ |\ h(x)$
2) Если $f(x)\ |\ (g(x) h(x))$, то $f(x)\ |\ h(x)$ 

**Доказательство**
Пусть $f(x) = a(x)h(x)$, $g(x) = b(x)h(x)$. По критерию взаимной простоты  $\exists u(x), g(x): f(x) u(x) + g(x) v(x) = 1$. Домножим на $h(x)$:
$$f(x)h(x)u(x) + g(x)h(x)v(x) = h(x)$$
$$f(x)b(x)g(x)u(x) + g(x)a(x)f(x)v(x) = h(x)$$
$$(f(x)g(x))(b(x)u(x) + a(x)v(x)) = h(x)$$
$\implies (f(x)g(x))\ |\ h(x)$



## Неприводимые (неразложимые) многочлены

> [!abstract] Неприводимый многочлен
> Многочлен $f(x) \in F[x]$ называется ==неприводимым== над полем $F$, если его нельзя разложить в произведение многочленов меньшей степени, то есть если $\forall f(x)=g(x)h(x)$ либо $\deg g(x) = \deg f(x)$, либо $h(x) = \deg f(x)$


> [!abstract] Разложимый многочлем
> Многочлен $f(x) \in F[x]$ ==приводим (разложим)== над полем $F$, если существует $f(x) = g(x)h(x)$, где $g(x), h(x) \in F[x]$

### Предложение
**Теорема**
Пусть $g$ неприводим над полем $F$ и $g\ |\ (h_1(x)h_2(x)\dots h_m(x))$. Тогда существует число $i$ такое, что $g\ |\ h_i(x)$

**Доказательство**
Б.И. - для $m = 1$ - очевидно

Ш.И. Предположим, что утверждение доказано для случая, когда менее $m$ сомножителей. 
Рассмотрим случай $m$ сомножителей. Пусть $d(x) = \text{НОД}(g(x), h_m(x))$. Тогда $\exists q(x): g(x) = q(x)d(x)$. По условию теоремы $g$ - неприводим, поэтому возможны два случая:
1. $\deg d(x) = \deg g$, тогда $g(x)$ и $g(x)$ - ассоциированы.
2. Если $d(x) = 1$, тогда $g(x)$ и $h_m(x)$ - взаимно просты, и, по доказанной лемме, $g(x)\ |\ h_1(x) \cdot \dots \cdot h_{m - 1}(x)$. Тогда по предположению индукции получаем, что найдётся $i$ такое, что $g(x)\ |\ h_i(x)$

### Теорема о разложении многочлена в произведение неприводимых многочленов
**Теорема**
Каждый многочлен однозначно раскладывается в произведение неприводимых многочленов, с точностью до перестановки сомножителей и ассоциированности.

**Доказательство существования**
Докажем индукцией по степени многочлена.
1. Если $f(x)$ - неприводим, то $f(x) = f(x)$
2. Пусть доказано для многочленов степени меньше $m$. При этом, если $f(x)$ разложим, то $f(x) = g(x) h(x)$. При этом $\deg g(x),\ \deg h(x) < \deg f(x)$, т.к. по предположению индукции $g(x)$ и $h(x)$ раскладываются в произведение неприводимых многочленов.

**Доказательство единственности**
Предположим, что есть два разложения для $f(x)$:
$$f(x) = g_1(x) \dots g_k(x) = h_1(x) \dots h_m(x)$$ 
Так как $g_1(x)$ неприводим и $g_1(x)\ |\ h_1(x) \dots h_m(x)$, то по доказанному выше предложению существует $j$ такое, что $g_1(x)\ |\ h_j(x)$. Перенумеруем $h(x)$ и будем считать $j = 1$. Тогда $g_1(x)\ |\ h_1(x)$. Так как $h_1(x) = q(x)g_1(x)$ и $h_1(x)$ неприводим, то $\deg h_1(x) = \deg g_1(x)$, то есть $h_1(x)$ и $g_1(x)$ ассоциированы.
$$g_1(x)g_2(x)\dots g_k(x) = cg_1(x)h_2(x)\dots h_m(x)$$
Получаем
$$g_2(x)\dots g_k(x) = ch_2(x) \dots h_m(x)$$
И продолжаем аналогичный процесс. Мы найдём для $g_2(x)$ ассоциированный многочлен $h_2(x)$, далее для $g_3(x)$, и т.д.



## Корни многочленов
### Теорема Безу
**Теоерма**
Если $f(x) \in F[x]$ и $c \in F$, то остаток от деления $f(x)$ на $(x - c)$ равен $f(c)$

**Доказательство**
$f(x) = q(x)(x - c) + r$. Остаток имеет степерь меньше, чем $\deg q(x)$. Подставим вместо $x$ $c$: $f(c) = q(c)(c - c) + r = r$


> [!abstract] Корень многочлена
> Число $c\in F$ называется ==корнем многочлена== $f(x) \in F[x]$, если $f(x) = 0$

### Основная теорема алгебры
**Теорема**
Любой многочлен $f(x) \in \mathbb{C}[x]$ степени не меньше, чем 1, имеет корень.

> [!important] Следствие из основной теоремы алгебры
> Если $f(x) \in F[x]$ имеет степень $n$, то $f(x)$ имеет ровно $n$ корней над полем $\mathbb C$ (с учетом кратности).



## Неприводимость над $\mathbb R$
### Лемма о сопряжённых с корнями
**Лемма**
Пусть $f(x) \in \mathbb R[x]$. Если $z\in \mathbb C$ является корнем $f(x)$, то и $\bar z$ тоже является корнем $f(x)$.

**Доказательство**
$f(x) = a_nx^n + \dots + a_0,\ (a_i \in \mathbb R)$. $z$ - корень $\implies f(z) = 0$. Рассмотрим $f(z) = a_nz^n + \dots + a_1z + a_0 = 0$. Возьмём сопряжённое обеих частей равенства:
$$\overline{f(z)} = \overline{a_nz^n + \dots + a_1z + a_0} = \bar 0$$
$$\bar a_n (\bar z^n) + (\bar a_{n - 1})(\bar z^{n - 1}) + \dots + \bar a_1 \bar z = 0$$
Так как все числа $a_i$ - вещественные, то $\bar a_i = a_i$. Тогда $f(\bar z)_ = 0$.

### Теорема о неразложимости над $\mathbb R$
**Теорема**
Над $R$ неразложимыми являются только многочлены первой степени и второй с отрицательным дискриминантом.

**Доказательство**
Так как $\mathbb R \subset \mathbb C$, то $f(x) \in \mathbb R[x]$ имеет в точности $n$ корней над полем $\mathbb C$. Множество корней можно разбить на два типа: вещественные и комплексные. Но по предыдущей лемме если у $f(x)$ есть комплексный корень, сопряжённый с ним также является корнем. Рассмотрим $(x - z)(x - \bar z)$. Заметим, что этот квадратный трёхчлен неразложим над $\mathbb R$, но имеет коэффициенты из $\mathbb R$.

Рассмотрим многочлен $f(x) = a_3x^3 + a_2 x^2 + a_1 x + a_0,\ f(x) \in \mathbb R[x]$. Возможны два случая: либо один кореньб действительный и два комплексных, либо все корни действительные. Если два корня комплексные, то он раскладывается на две неразложимые над $\mathbb R$. Ситуации, когда три корня комплексные, а коэффициенты действительные быть не может в силу предыдущей леммы. По индукции - многочлены более высоких степеней раскладываются аналогично.

## Разложение многочленов над $\mathbb Q$ и над $\mathbb Z$

> [!abstract] Примитивные многочлены
> Многочлен $f(x) \in \mathbb Z[x]$ называется ==примитивным==, если НОД его коэффициентов равен $1$.

### Лемма Гаусса
**Лемма**
Произведение примитивных многочленов $g(x) \cdot h(x) = f(x)$ является примитивным.

**Доказательство**
$g(x) = b_kx^k + \dots + b_1x + b_0$. При этом $\text{НОД}(b_k, \dots, b_0) = 1$ и $h(x) = c_kx^k + \dots + c_1x + c_0$,  $\text{НОД}(c_k, \dots, c_0) = 1$. $f(x) = g(x) \cdot h(x)$, то есть $a_n = c_mb_{n - m}$, $\ a_{n - 1} = c_{m - 1}b_m + c_{m - 1}b_{n - m}$, $a_i = c_0b_i + c_1b_{i - 1} + \dots + c_ib_{k - i}$. Пусть $f(x)$ - не примитивный. Тогда $\exists d \neq 1$ такое, что $d$ делит любой коэффициент $f(x)$. Будем считать, что $d$ - простое. Возьмём наименьший индекс $i_0$ такой, что $c_{i_0}$ не делится на $d$ (если все коэффициенты $h(x)$ делятся на $d$, то $h(x)$ - не примитивный). По аналогии возьмём $j_0$ такой,что $b_{j_0}$ не делится на $d$. Рассмотрим коэффициент $a_{i_0 + j_0}$ при степени $x^{i_0 + j_0}$.

$$a_{i_0 + j_0} = c_0b_{i_0 + j_0} + c_1b_{i_0 - 1} + \dots + c_{i_0}b_{j_0} + c_{i_0 + 1}b_{j_0 -1} + \dots + c_{i_0 + j_0}b_0$$. Тогда $c_{i_0}b_{j_0}$ не делится на $d$, то есть пришли к противоречию.

### Теорема о разложимости над $Q$
**Теорема**
Пусть $f(x) \in \mathbb Z[x]$. $f(x)$ разложим над $\mathbb Z$ тогда и только тогда, когда он разложим над $\mathbb Q$.

**Доказательство**
От противного. Пусть $f(x) = a_nx^n + a_{n - 1} x^{n-1} + \dots + a_1x + a_0,\ f(x) \in \mathbb Z[x]$ разложим над $Q$, то есть $f(x) = g(x) h(x) \in \mathbb Q[x]$. Тогда $g(x) = \dfrac {c_1}{b_1} g_1(x)$ и $h\left(x\right) = \dfrac {c_2}{b_2} h_1(x)$. При этом $g_1(x)$ и $h_1(x)$ - примитивные. Тогда $f(x)= a_nx^n + \dots + a_1x + a_0 = g(x) h(x) = \dfrac{c_1 c_2}{b_1 b_2} g_1(x) h_1(x)$. По лемме Гаусса $g_1(x) h_1(x)$ - примитивный. Если $\dfrac {c_1}{c_2} = \dfrac p q$, то это означает, что $\dfrac p q f_1(x)$ - многочлен, то при $q \neq 1$ хотя бы один из коэффициентов которого - рациональная дробь.

### Теорема: признак Эйзенштейна
**Теорема**
Пусть $f(x) \in \mathbb Z[x]$ и $f(x) = a_n x^n + a_{n - 1}x^{n - 1} + \dots + a_1x + a_0$ и существует такое простое число $p$, что:
1) $p$ не делит $a_n$
2) $p$ делит все остальные $a_i\ (i = 0, 1, \dots, n - 1)$
3) $p^2$ не делит $a_0$

Тогда $f(x)$ неприводим над $\mathbb Q$./

**Доказательство**
Пусть $f(x) = a_n x^n + \dots + a_0 \in \mathbb Z[x]$ и пусть выполняется условие признака. Тогда предположим, что $f(x)$ - разложим, то есть $f(x) = g(x) h(x)$, где $g(x) = b_k x^k + \dots + b_1 x + b_0$ и $h(x) = c_m x ^m + \dots + c_1 x + c_0$.
Тогда $p^2$ не делит $c_0$ $\implies$ либо $p\ |\ c_0$ и $p$ не делит $b_0$, либо наоборот. Пусть $p\ |\ c_0$ и $p$ не делит $b_0$. Тогда $a_1 = b_1c_0 + c_1 b_0$, отсюда, т.к. $p\ |\ a_1$, то $p\ |\ c_1$, далее, $a_2 = b_2 c_0 + c_1 b_1 + c_2 b_0$, отсюда $p\ |\ c_2$. Продолжая эти рассуждения, получаем что $a_m = b_m c_0 + c_m b_1 + \dots + c_m b_0$, то есть $p | c_m$, то есть $p\ |\ a_n$ - противоречие.
### Теорема о виде рациональных корней
**Теорема**
Число $\dfrac p q$ является корнем многочлена $f(x) = a_nx^n + \dots + a_1x + a_0$, если $q\ |\ a_n$ и $p\ |\ a_0$

**Доказательство**
Пусть $\dfrac p q$ является корнем ($p$ и $q$ - взаимно просты). Подставим $f\left(\dfrac p q\right)= a_n (\dfrac p q)^n + \dots + a_1\left(\dfrac p q\right)+ a_0 = 0$. Заметим, что правая часть делится на $p$ $\implies$ $a_0$ делится на $p$. Домножим на $q^n$, $a_n$ аналогично делится на $q$.
## Производная многочлена
> [!abstract] Производная многочлена
> ==Производной многочлена== $f(x) = a_nx^n + a_{n - 1}x^{n - 1} + \dots + a_1x + a_0$ называется многочлен $f'(x) = na_nx^{n - 1} + (n - 1)a_{n - 1}x^{n - 1} + \dots + 2a_2x + a_1$

### Свойства производной многочлена
1. $(f(x) \pm g(x))' = f'(x) + g'(x)$
2. $(f(x)g(x))' = f'(x)g(x) + f(x)g'(x)$
3. $(Cf(x))' = cf'(x)$

**Доказательство**
Можно вывести из определения производной.

### Кратные корни

> [!abstract] Кратный корень
> Число $c$ является ==корнем многочлена $f(x)$ кратности $k$==, если множитель $(x - c)$ входит в разложение $f(x)$ в точности $k$ раз.

### Теорема о кратности корня производной
**Теорема**
Пусть число $c$ является корнем многочлена $f(x)$ кратности $k \geq 1$, тогда число $c$ является корнем многочлена $f'(x)$ кратности $k - 1$.

**Доказательство**
$$f(x) = (x - c)^kg(x)$, при этом $(x - c)$ не делит $g(x)$$
$$f'(x) = k(x - c)^{k - 1} g(x) + (x - c)^kg'(x)$$

В обратную сторону: пусть $c$ является корнем кратности $m$. По доказанному, $c$ - корень кратности $m - 1$ для $f'(x)$. Отсюда получаем, что $k = m$ %% не понял %%

### Теорема
**Теорема**
Пусть $d(x) = \text{НОД}(f(x),\ f'(x))$. Тогда $d(x)$ содержит все кратные множители многочлена $f(x)$

**Доказательство**
Разложим многочлен над полем $\mathbb C$. Очевидно, что кратные корни, и только она входят в $f(x)$ и $f'(x)$

### Теорема: интерполяционный многочлен Лагранжа
**Теорема**
Многочлен $f(x)$ степени $n$ однозначно определяется своими значениями в $n + 1$ попарно различных точках.

**Доказательство**
Единственность: пусть $f(x)$ и $g(x)$ имеют степень $n$ и совпадают в точках $x_0, x_1, \dots, x_n$. Тогда если $f(x) = g(x)$, то $h(x) = f(x) - g(x)$ равен $0$ в этих точках. Но тогда это многочлен степени не выше $n$, и он имеет как минимум $n+1$ корень. Но т.к. ненулевой многочлен не может иметь корней больше, чем его степень, то $h(x) = 0 \implies f(x) = g(x)$

Существование: можно показать, что $$f(x) = f(x_0)\cdot \left( \dfrac {(x - x_1)(x - x_2)\dots(x - x_n)}{(x_0 - x_1)(x_0 - x_2)\dots (x_0 - x_n)}\right) + f(x_1)\cdot \left( \dfrac {(x - x_0)(x - x_2)\dots(x - x_n)}{(x_1 - x_0)(x_1 - x_2)\dots (x_1 - x_n)}\right) + f(x_2)\cdot \left( \dfrac {(x - x_0)(x - x_1)(x_3 - x_0)\dots(x - x_n)}{(x_2 - x_1)(x_2 - x_3)\dots (x_2 - x_n)}\right) + \dots$$

Найдём $f(x_0)$: в первом слагаемом все скобки сократятся и останется $f(x_0)$, а остальные слагаемые обнулятся из-за множителя $(x - x_0)$.
Когда подставляется $x = x_1$, остаётся только второе слагаемое, равное $f(x_1)$, остальные обнуляются.
Получаем многочлен, который в точках $x_0, x_1, \dots, x_n$ совпадает со значениями $f(x)$, и поэтому равен $f(x)$.

Многочлен, построенный в доказательстве теоремы, называется интерполяционным многочленом Лагранжа.

# Замена базиса
## Базисы. Матрицы линейного оператора. Матрица перехода.

> [!tip] Напоминание
> Пусть заданы базисы в пространствах $P$ и $Q$, и $A: P \mapsto Q$ - линейный оператор. Матрица линейного оператора в базисе $P$: $p_1, \dots, p_n$ получается следующим образом: столбцами этой матрицы являются векторы $A(p_i)$. $A_{P, Q}$ - матрица оператора в базисах $P$ и $Q$. $[x]_p$ - вектор-столбец в базисе $P$. Тогда $[A(x)]_Q = A_{P, Q}[x]_P$


> [!abstract] Матрица перехода
> Дано линейное пространство $V$ и даны два его базиса: $P$ и $Q$. ==Матрица перехода== от базиса $P$ к базису $Q$ получается следущим образом: координаты векторов базиса $Q$ записываются как столбцы в базисе $P$. На матрицу перехода можно смотреть, как на матрицу линейного оператора $A_{P, Q}$.

### Теорема: преобразование кординат при замене базиса
**Теорема**
Пусть $P$ и $Q$ - базисы пространства $V$. Тогда для любого вектора $x \in V$ имеем следующую формулу: $[x]_P = T_{P,Q}[x]_Q$.

**Доказательство**
Рассмотрим разложение вектора $x$ в базисах $P$ и $Q$. Так как это один и тот же вектор, получаем равенство $x = x_1p_1 + \dots + x_np_n = x_1q_1 + \dots + x_nq_n$. Тогда по определению матрицы перехода $q_1 = t_{11}p_1 + t_{21}p_2 + \dots + t_{n1}p_n,\ \dots,$ $q_n = t_{1n}p_1 + t_{2n}p_2 + \dots + t_{nn}p_n$. $$x_1p_1 + \dots + x_np_n = x_1(t_{11}p_1 + t_{21}p_2 + \dots +t_{n1}p_n) + \dots + $$$$+\ x_n(t_{1n}p_1 + t_{2n}p_2 + \dots +t_{nn}p_n) =$$
$$= (x_1t_{11} + \dots + x_nt_{1n})p_1 + \dots + (x_1t_{n1} + \dots + x_nt_{nn})p_n$$
$$\begin{cases}x_1 = x_1t_11 + \dots x_nt_{1n}\\ \dots\\ x_n = x_1t_{n1} + \dots + x_{n}t_{nn}\end{cases}$$
Тогда $\begin{pmatrix} x_1 & \dots & x_n\end{pmatrix} = \begin{pmatrix} t_11 & \dots & t_1n \\ \dots & \dots & \dots &  \\ t_{n1} & \dots & t_{nn}\end{pmatrix}\begin{pmatrix}x_1 \\ \dots \\ x_n\end{pmatrix}$, тогда $[x]_P = T_{PQ}[x]_Q$.

Очевидно, что так же можно построить и матрицу обратного перехода $T_{QP}$, $T_{QP} = (T_{PQ})^{-1}$

### Теорема: преобразование матрицы линейного оператора при замене базиса
**Теорема**
Пусть в пространстве $V$ заданы два базиса $P$ и $Q$, $A$ - линейный оператор. $A_P$ - матрица оператора $A$ в базисе $P$. Тогда $A_Q = T_{QP}A_PT_{PQ}$.

**Доказательство**
$$[Ax]_P = A_P[x]_P = A_PT_{PQ}[x]_Q$$$$[Ax]_P=T_{PQ} [Ax]_Q = T_{PQ}[Ax]_P$$
Тогда $$\forall x: A_P[x]_P = A_PT_{PQ}[x]_Q = T_{PQ} [Ax]_Q = T_{PQ}[Ax]_P$$ $$T_{PQ}A_Q = A_PT_{PQ}$$
$$A_{Q} = (T_{PQ})^{-1}A_PT_{PQ} = T_{QP}A_PT_{PQ}$$



### Подобные матрицы

> [!abstract] Подобные матрицы
> Матрицы $A$ и $B$ называются ==подобными==, если существует невырожденная матрица $T$ такая, что $B = T^{-1}AT$

> [!tip] 
> Матрицы оператора в разных базисах являются подобными.

# Линейное отображение в пространстве

> [!error] Алярма
> С этого момента Расин читает лекции по презентациям ___Гейна___, а не Волкова.

## Сопряжённое отображение

> [!abstract] Сопряженное отображение
> Пусть $L_1$ и $L_2$ - пространства со скалярным произведением. Пусть $f: L_1 \mapsto L_2$ - некоторая функция. Функция $g: L_2 \mapsto L_1$ ==сопряжена== с функцией $f$, если для любой пары векторов $x$ и $y$ имеет место $(f(x), y) = (x, g(y))$. Сопряжённую к $f$ функцию принято обозначать $f^*$.

### Теорема о единственности сопряжённой функции
**Теорема**
Если для функции $f$ существует сопряжённая функция $g$, то $g$ - единственна.

**Доказательство**
От противного. Пусть сопряжённых функций две: $g_1$ и $g_2$. Тогда $\forall x,y: (f(x), y) = (x, g_1(y)),\ (f(x), y) = (x, g_2(y))$. Тогда $(x, g_1(y)) = (x, g_2(y)) \implies (x, g_1(y)) - (x, g_2(y)) = 0$. Тогда $(x, g_1(y) - g_2(y)) = 0$. Но так как это выполняется для всех $x$, то значения $g_1$ и $g_2$ совпадают на всей области определения.


### Теорема о линейности сопряжённой функции
**Теорема**
Если у функции $f$ существует сопряжённая $g$, то $g$ - линейная

**Доказательство**
$\forall x, y: (f(x), y) = (x, g(y))$. Проверяем свойства линейности:
1) $\forall y_1, y_2 \in L_2$ покажем, что $g(y_1 + y_2) = g(y_1) + g(y_2)$. $f\forall x \in L_1 (f(x), y_1 + y_2) = (x, g(y_1 + y_2))$. Тогда $(f(x), y_1 + y_2) = (f(x), y_1 + y_2) = (f(x), y_1) + (f(x), y_2) = (x,g(y_1)) + (x, g(y_2))$. Поскольку это имеет место для любого $x$, то $g(y_1 + y_2) = g(y_1) + g(y_2)$
2) Расин сказал проверить самостоятельно. Я услышал: "киньте в меня пулл реквестом".

### Теорема о повторном взятии сопряжённой функции
**Теорема**
Если $f$ имеет сопряжённую $f^*$, то $f^{**} = f$.

**Доказатесьтво**
Надо проверить, что $\forall (x, y): (f*(y), x) = (y, f(x))$.
$$(f^*(y), x) = \overline{(x, f*(y))} = \overline{(f(x), y)} = \overline{\overline{(y, f(x))}} = (y, f(x))$$

**Следствие**
Если для функции $f$ существует сопряжённая функция, то $f$ - линейная.

### Теорема о сопряжённом отображении в пространстве со скалярным произведением
**Теорема**
Если $f$ - линейное отображение из конечномерного пространства $L_1$ в пространство $L_2$ со скалярным произведением, то для $f$ существует сопряжённое отображение.

**Доказательство**
Пусть $u_1, \dots, u_n$ - ортонормированный базис в $L_1$, $v_1, \dots, v_n$ - ОНБ в $L_2$. Тогда $\forall x, y: (f(x), y) = [f(x)^T]\overline{[y]} = [f\cdot x]^T \overline{[y]} = [x]^T[f]^T\overline{[y]}$ $= [x]^T[f]^T\overline{[y]} = [x]^T\overline{\overline{[f]^T}}[y] = (x, \overline{[f]^T}[y])$- по формуле скалярного произведения в ОНБ. Тогда $(a, b) = a_1\overline{b}_1 + a_2\overline b_2 + \dots + a_n\overline b_n$ $= (a_1, \dots, a_n)\overline{ \begin{pmatrix} b_1 \\ \dots \\ b_n\end{pmatrix}}$. Мы получили, что линейный оператор с матрицей $f$ имеет сопряжённый оператор, причём, если базисы ортонормированные, матрица сопряжённого оператора является сопряжённо-транспонированной к исходной.

### Теорема: свойства сопряжения
**Теорема**
Пусть $f ,g , h$ - линейные операторы из конечномерного пространства $L_1$ в $L_2$, и $\alpha$ - скаляр. Тогда 
1) $(f + g)^* = f^* + g^*$
2) $(\alpha f)^* = \overline\alpha f^*$
3) $(fh)^* = h^* f^*$

**Доказательство**
3) $(fh(x), y) = (h(x), f^*(y)) = (x, h^* f^*(y))$

## Изометрические отображения

> [!abstract] Изометрическое отображение
> Линейное отображение $f: L_1 \mapsto L_2$ называется ==изометрическим==, если $\forall x, y: (x, y) = (f(x),  f(y))$

> [!tip] Пример
> Изометрическое отображение в $\mathbb R^2$ или в $\mathbb R^3$ сохраняет углы между векторами и отношения их длин. Пример такого отображения: поворот плоскости на угол $\alpha$ в $\mathbb R^2$, или отражение относительно оси $Ox$.

### Теорема: критерий изометричности отображения
**Теорема**
Линейное отображение $f: L_1\mapsto L_2$ изометрично $\iff \forall x \in L_1: |f(x)| = |x|$.

**Доказательство**
$\implies$. $(x, x) = (f(x), f(x)) \iff |x|^2  =|f(x)|^2 \iff |x| = |f(x)|$.

$\impliedby$. Пусть $\forall x \in L_1: |f(x)| = |x|$, то есть $(f(x), f(x)) = (x, x)$. Подставим вместо $x$ вектор $x + y$. Получим, что $(f(x + y), f(x + y)) = (x + y, x+ y)$. Воспользуемся свойством линейности: $(f(x) + f(y), f(x) + f(y)) = (x + y, x + y)$. $(f(x), f(x)) + (f(x), f(y)) + (f(y), f(x)) + (f(y), f(y))$ $= (x, x) + (x, y_ + (y, x) + (y, y)$. Приводим подобные: $(f(x), f(y)) + (f(y), f(x)) = (x , y) + (y, x)$. Рассмотрим два случая:
1) Пространство евклидово. Тогда $(a, b) = (b, a)$. Получаем $2(f(x), f(y)) = 2(x, y)$, что фактически является определением изометричности.
2) Пространство унитарно. Вместо $x$ подставим вектор $ix$. Получим $(f(ix), f(y)) + (f(y), f(ix)) = (ix, y) + (y, ix)$. $i(f(x), f(y)) - \overline i (f(y), f(x)) = i(x, y) + \overline i (y, x)$. $(f(x), f(y)) - (f(y), f(x)) = (x, y) - (y, x)$. Получаем систему уравнений $$\begin{cases} (f(x), f(y)) - (f(y), f(x)) = (x, y) - (y, x) \\ (f(x), f(y)) - (f(y), f(x)) = (x, y) + (y, x)\end{cases}
$$
Тогда $2(f(x), f(y)) = 2(x, y) \implies (f(x), f(y)) = (x, y)$

### Теорема: второй критерий изометричности
**Теорема**
Линейное отображение $f: L_1\mapsto L_2$ изометрично $f^* \cdot f : L_1\mapsto L_1$ - тождественное отображение.

**Доказательство**
$\implies$. $\forall x, y: (x, y) = (f(x), f(y)) = (x, f^* f(y)) \implies f^* f = y$, т.е. отображение тождественно.

### Теорема
**Теорема**
1) Если $f$ - изометрическое отображение из $L_1$ в $L_2$, то любую ортонормированную систему векторов пространства $L_1$ отображение $f$ переводит в ортонормированную систему в $L_2$.
2) Если $f$ - линейное отображение из $L_1$ в $L_2$ и оно переводит некоторый ОНБ в ОНБ, то оно изометрично.

**Доказательство**
1) Следует из определения изометричности. $(x, y) = (f(x), f(y)) = 0$
2) $u_1, u_2, \dots, u_n$ - ОНБ в $L_1$. $v_1 = f(u_1), v_2 = f(u_2), \dots, v_n = f(u_n)$ - ОНБ в $L_2$. Возьмём вектор $x = a_1u_1 + \dots + a_nu_n$. $|x| = \sqrt{a_1^2 + \dots + a_n^2}$ (так как $u_1, \dots, u_n$ - ОНБ). В силу линейности $f(x) = f(a_1u_1 + \dots + a_nu_n)=$$= a_1f(u_1) + \dots + a_nf(u_n) = a_1v_1 + \dots + a_n v_n$. $|f(x)| = \sqrt{a_1^2 + \dots + a_n^2}$, т.к. $v_1, \dots, v_n$ - ОНБ. Получаем, что $|x| = |f(x)|$, что является условием изометричности.


## Самосопряжённые операторы

> [!abstract] Самосопряжённое преобразование
> Линейное преобразование называется ==самосопряжённым==, если $f = f^*$


> [!abstract] Собственный вектор
> Пусть $f$ - лин. преобразование лин. пространства $L$ над полем $F$. Вектор $x \in L,\ x \neq 0$ называется ==собственным==, если $\exists a \in F: f(x) = ax$, при этом число $a$ называется ==собственным значением== оператора $f$. 


### Нахождение собственных векторов
$$[f] = \begin{pmatrix} a_{11} & \dots & a_{1n} \\ \dots & \dots & \dots  \\ a_{n1} & \dots & a_{nn}\end{pmatrix}$$
Перейдём к системе уравнений $\begin{pmatrix} a_{11} & \dots & a_{1n} \\ \dots & \dots & \dots  \\ a_{n1} & \dots & a_{nn}\end{pmatrix}\begin{pmatrix} y_1  \\ \dots \\ y_n\end{pmatrix}$.
$$\begin{cases} a_{11}y_1 + \dots + a_{1n} y_n = ay_1\\ a_{21}y_1 + \dots + a_{2n}y_n= ay_2\\ \dots \\ a_{n1}y_1 + \dots + a_{nn} y_n = ay_n\end{cases}$$
Построим матрицу системы: $$C = \begin{pmatrix} a_{11} - a  & a_{12}  & \dots  & a_{1n} \\ a_{21} & a_{22} - a & \dots & a_{2n} \\ \dots & \dots & \dots & \dots \\ a_{n1}  & a_{n2} & \dots & a_{nn} - a\end{pmatrix}$$
Матрица $C: [f] - aE$ называется ==характеристической матрицей оператора==. Поскольку собственный вектор $y\neq 0$, то система с матрицей имеет ненулевое решение, то есть её определитель навен $0$. В противном случае по правилу Крамера система имеет единственное нулевое решение. Таким образом, число $a$ является собственным значением линейного оператора $\iff |[f] - aE| = 0$. 


> [!abstract] Характеристический многочлен
> Определитель характеристической матрицы называетсфя ==характеристическим многочленом==.

### Теорема о собственных числах
**Теорема**
Собственные значения линейного оператора являются корнями его характеристического многочлена. Каждый корень характеристического многочлена - собственное число линейного преобразования $f$.

**Доказательство**
$\implies$. См. выше - сведение к матрице системы?
$\impliedby$. Пусть $A$ - корень характеристического многочлена. Тогда $|[f] - aE| = 0$. Тогда ранг характеристической матрицы меньше числа неизвестных $n$. Таким образом, размерность пространства решений равна $n - r$, то есть существует ненулевое решение $y = (y_1, \dots, y_n)$. Это означает, что $f[y] = a[y]$.

### Пример нахождения собственных значений и собственных векторов
$A = \begin{pmatrix} 1  & 1 \\ 1 & 1\end{pmatrix}$. 
1) Составляем характеристическое уравнение. $\begin{vmatrix} 1 - a  & 1 \\ 1  & 1 - a\end{vmatrix} = (1 - a)^2 -1 = 0$. Тогда $a_1 = 0, a_2 = 2$. 
2) Для каждого собственного значения находим собственный вектор. $(A - a_1E)\begin{pmatrix} y_1  \\ y_2\end{pmatrix} = \begin{pmatrix}0 \\ 0\end{pmatrix}$. Тогда $\begin{pmatrix} 1  & 1 \\ 1 & 1\end{pmatrix}\begin{pmatrix} y_1 \\ y_2\end{pmatrix} = \begin{pmatrix} 0  \\ 0\end{pmatrix}$. Решаем систему, получаем собственнй вектор.

### Теорема о независимости хар. многочлена от выбора базиса
**Теорема**
Характеристический многочлен не зависит от выбора базиса.

**Доказательство**
$P$ и $Q$ - базисы. Тогда $[f]_Q = T_{QP}[f]_PT_{PQ} = T^{-1}[f]_PT$.
$$|[f]_Q - aE| = |T^{-1}[f]_PT - aE| = |T^{-1}[f]_PT - aT^{-1} T| = |[f]_P - aE$$

**Следствие**
Собственные значения и собственне векторы не зависят от выбора базиса, то есть однозначно определяются линейным оператором.

### Теорема о корнях характеристического многочлена самосопряжённого оператора
**Теорема**
Все корни характеристического многочлена самосопряжённого линейного оператора - действительные числа. 

**Доказательство**
Пусть $a$ - собственное значение, соответствующее вектору $y$. Тогда $f(y) = ay$. $a(y, y) = (ay, y) = (f(y), y) = (y, f^*(y)) = (y, f(y)) = (y, ay) = \bar a (y, y)$. Тогда $a = \bar a$, то есть $a\in \mathbb R$.


### Теорема: критерий самосопряжённости
**Теорема**
Линейное преобразование конечномерного пространства со скалярным произведением самосопряжённое $\iff$ существует ОНБ из собственных векторов, собственные числа которых действительны.

**Доказательство**
$\implies$. Индукция по размерности пространства. Б.и.: $\dim L =1$. Возьмём базисный вектор $u$. Тогда этот базисный вектор - собственный с некторым собственным значением $a$. Ш.и.: пусть утверждение доказано для размерности $\dim L = n - 1$. Докажем для пространства размерности $n$. По предыдущей теореме все корни хар. многочлена действительны, значит есть собственное значение $a_1$, которому соответствует собственный вектор $u_1$. Рассмотрим подпространство $[u_1]^\perp$ - ортогональное дополнение. По теореме об ортогональном дополнении, $L = <u_1>\oplus{<u_1>}^\perp$. Пусть $x$ $\in [u_1]^\perp$. Тогда $(f(x), u_1) = (x, f^*(u_1)) = (x, f(u_1)) = (x, au_1) = a(x, u_1) = 0$ - т.к. $x$ из ортогонального дополнения. Мы показали, что если $x \in [u_1]^\perp$, то $f(x)$ остаётся в том же пространстве. Таким образом, $f$ на $[u_1]^\perp$ является самосопряжённым линейным оператором. Поскольку $\dim [u_1]^\perp = n - 1$, то по предположению индукции в $[u_1]^\perp$ есть ОНБ $u-2, \dots, u_n$. Тогда $u_1, \dots, u_n$ - ОНБ в $L$.

$\impliedby$. Пусть $u_1, u_2, \dots, u_n$ - ОНБ собственных вектором и $a_1, \dots, a_n$ - собственные значения. $f(u_1) = a_1u_1, f(u_2) = au_2,\dots,  f(u_n) = a_nu_n$. Тогда $f(u_1) = a_1u_1 = a_1 \cdot u_1 + 0 \cdot u_2 + \dots + 0\cdot u_n$. Очевидно, что матрица оператора $f$ равна сопряжённо-транспонированной, так как она диагональная и все элементы на главной диагонали действительные. Тогда $f$ - самосопряжённый оператор.

## Несовместные СЛУ
### Решение несовместной системы
Пусть дана несовместная система линейных уравнений. $$\begin{cases} a_{11}x_1 + \dots + a_{1n}x_n = b_1 \\
a_{21}x_1 + \dots + a_{2n}x_n = b_2 \\
\dots \\
a_{m1}x_1 + \dots + a_{mn}x_n = b_m\end{cases}$$
Будем смотреть на матрицу системы как на матрицу линейного оператора. Пусть задан некоторый базис $e_1, \dots, e_n$. Столбцы матрицы $A$ - координаты образов векторов базиса. $u_1 = Ae_1, u_2 = Ae_2, \dots, u_n = Ae_n$. 

Вектор $Ax$ лежит в образе оператора $A$, то есть систему можно переписать следующим образом: $Ax = b \implies$ $$\begin{pmatrix}a_{11} \\ \dots \\ a_{m1}\end{pmatrix}x_1 + \begin{pmatrix}a_{12} \\ \dots \\ a_{m2}\end{pmatrix}x_2 + \dots + \begin{pmatrix}a_{1n} \\ \dots \\ a_{mn}\end{pmatrix} x_n = \begin{pmatrix} b_1 \\ \dots \\ b_n\end{pmatrix}$$

Система несовместна $\iff$ $b$ не является линейной комбинацией векторов $u_1, \dots, u_n$, и, следовательно $b\notin \text{Im } A$. Тогда (псевдо)решением несовместной системы можно считать такой вектор $x^*$, что $|Ax^* - b|$ имеет минимальное значение.

> [!abstract] (Псевдо)решение системы
> ==Псевдорешением== несовместной системы уравнений является такой вектор $x^*$, что $|Ax^* - b|$ имеет наименьшее значение. ($A$ - матрица системы, $b$ - столбец свободных членов)

Геометрически понятно, что $$\begin{cases} (u_1, b - y^*) = 0 \\ (u_2, b - y^*) = 0 \\ \dots \\ (u_n, b - y^*) = 0\end{cases}$$ эта система однородна, поэтому она всегда имеет решение. Раскроем скобки: $$\begin{cases} (u_1, y^*) = (u_1, b) \\ (u_2, y^*) = (u_2, b) \\ \dots \\ (u_m, y^*) = (u_m, b)\end{cases}$$
Тогда по свойствам скалярного произведения $$\begin{cases} u_1^T y^* = u_1^Tb \\ \dots \\ u_m^Ty^* = u_m^T b\end{cases}$$$$\begin{cases} (Ae_1)^T Ax^* = (Ae_1)^Tb\\ \dots \\ (Ae_m)^TAx^* = (Ae_m)^T b\end{cases}$$ $$\begin{cases} e_1^T A^T Ax^* = e_1^T A^T b\\ \dots \\ e_m^T A^T Ax^* = e_m^T A^T b\end{cases}$$
Первое уравнение означает, что векторы $A^TAx^*$ и $A^Tb$ имеют одинаковые координаты. Второе уравнение означает, что векторы $A^TAx^*$ и $A^Tb$ имеют одинаковые координаты. $\dots$. $m$-е уравнение означает, что векторы $A^TAx^*$ и $A^Tb$ имеют одинаковые координаты. Следовательно векторы $A^TAx^*$ и $A^Tb$ равны. Мы получили систему уравнений $A^TAx^* = A^Tb$. Она совместна, т.к. кратчайшее расстояние между векторами существует. Решение этой системы - $x^*$ - является её псевдорешением.

При этом была также решена задача поиска вектора $x^*$, который минимизирует расстояние до вектора $b$.

### Метод наименьших квадратов
**нет блин квадрат наименьших методов**
Пусть дано множество точек плоскости $(x_1, y_1), \dots, (x_n, y_n)$. Нужно найти прямую, которая минимизирует сумму квадратов расстояний от этой прямой до каждой из этих точек.

Пусть $y = kx + b$ - уравнение данной прямой. $S = \min\sum\limits_{i = 1}^n (y_i - (kx + b))^2$. Нам неизвестны коэффициенты $k$ и $b$. Тогда можно составить систему $\begin{cases}\dfrac{\partial S}{\partial k} = 0 \\ \dfrac{\partial S}{\partial b} = 0\end{cases}$
Если случай не двумерный, нужно найти приближённое решение в виде $y = a_1x_1 + \dots + a_nx_n$. $(x_{11}, \dots, x_{1n}\ ;\ y_1)$, $\dots$, $(x_{m1}, \dots, x_{1n}\ ;\ y)$.
Тогда нужно решить систему $$\begin{cases} y_1 = a_1x_{11} + \dots + a_nx_{1n} \\ y_2 = a_1x_{21} + \dots + a_nx_{2n} \\ \dots \\ y_m = a_1x_{m1} + \dots + a_nx_{mn}\end{cases}$$
Тогда нужно решить несовместную систему с $A = \begin{pmatrix} x_11 & \dots & x_{1n} \\ x_{21} & \dots & x_{2n}  \\ \dots & \dots & \dots  \\  x_{m1} & \dots & x_{mn}\end{pmatrix}$ и $b = \begin{pmatrix} y_1 \\ y_2 \\ \dots \\ y_m\end{pmatrix}$




# Сингулярное разложение
## Сингулярное представление линейного оtображения

### Введение %% внутривенное %%
Ранее было показано, что изометрическое отображение переводит любой ОНБ в ОНБ. Очевидно, что для произвольного линейного оператора такое не обязательно выполняется.

Можно ли для данного отображения $f: L_1 \mapsto L_2$ в $L_1$ подобрать такой ОНБ, который переводится в ортогональную систему векторов $L_2$?

Пусть существует такой базис $u_1, u_2, u_3$. Тогда $b_1 = f(u_1), b_2 = f(u_2), b_3 = f(u_3)$, $b_1, b_2, b_3$ - ортогональны. Если теперь поделить $b_1, b_2, b_3$ на длины, то получим ортонормированную систему векторов $v_1, v_2, v_3$. Тогда получим числа $\sigma_1, \sigma_2, \sigma_3$ такие, что $f(u_1) = \sigma_1v_1,\ f(u_2) = \sigma_2v_2,\ f(u_3) = \sigma_3v_3$. Это похоже на самосопряжённый оператор. ![](attachments/Pasted%20image%2020230404140048.png)

Для каждого отображения $f$ можно рассмотреть отображение $f\circ f^*$. Это отображение самосопряжённое.

### Лемма
**Лемма**
%% чат гпт %%Бро, понимаешь, есть два пространства $L_1$ и $L_2$, они конечномерные и со скалярным произведением. И есть еще одно отображение $f$, которое линейное и переводит векторы из $L_1$ в $L_2$. Тогда $\ker f\circ f^* = \ker f$

**Доказательство**
$\implies$. Пусть $x \in \ker f$, то есть $f(x) = 0$. Тогда $(f\circ f^)(x) = f^*(f(x)) = f^*(0) = 0 \implies x \in \ker f^*$.

$\impliedby$. Пусть $x\in \ker f \circ f^*$. Тогда рассмотрим $(f(x), f(x)) = (x, f^*(f(x))$ $= (x, (f\circ f^*)(x)) = (x, 0) = 0$

**Следствие**
$\text{r}(f)$ - ранг оператора $f$.
Тогда $\text{r }(f) = \text{r}(f^*)$.

**Доказательство следствия**
По теореме о размерности ядра и образа (о ранге и дефекте) линейного оператора, $\text{r}(f) + \dim\ker f = r(f\circ f^*) + \dim\ker (f\circ f^*) = \dim L_1$. Тогда размерности образов этих преобразований равны.


### Теорема о сингулярном разложении
**Теорема**
Пусть $L_1$, $L_2$ - конечномерные пространства со скалярным произведением, $f: L_1 \mapsto L_2$, $f$ ненулевое. Пусть $m = \dim L_1$, $n = \dim L_2$, $r$ - ранг отображения $f$. Тогда существуют ОНБ $u_1, u_2, \dots, u_n$ в $L_1$ и ОНБ $v_1, \dots, v_n$ в $L_2$ такие, что $\begin{cases} f(u_i) = \sigma_iv_i &|\ 1 \leq i \leq r \\ f(u_i) = 0 & |\ r < i \leq m\end{cases}$. При этом числа $\sigma_i$ определены однозначно и не зависят от выбора базиса $u_1, \dots, u_m$. При этом числа $\sigma_i$ называются ==сингулярными числами== оператора.

**Доказательство**
$f\circ f^* : L_1\mapsto L_1$ - самосопряжённый оператор, так как $(f\circ f^*)^* = (f^*)^* \circ (f^*) = f\circ f^*$. Поэтому в $L_1$ существует ОНБ $u_1, u_2, \dots, u_n$ из собственных векторов оператора $f\circ f^*$. Тогда по доказанному выше следствию $\,r(f\circ f^*) = \,r(f) = \,r$. При этом только $\,r$ собственных чисел отличны от нуля. Пусть $a_1, \dots, a_m$ - собственные числа данных собственных векторов. Пусть $f(u_i) = z_i\ (i = 1\dots m)$. Тогда $(z_i, z_j) = (f(u_i), f(u_j) = (u_i, f^*(f(u_j))) =$ $(u_i, (f\circ f^*)(u_j)) = (u_j, \bar a_ju_j) = \bar a_j(u_i, u_j)) = 0$. Тогда $(z_i, z_j)\neq 0 \implies z_i \neq 0$.
При $i = j$ $(z_i, z_j) = a_i(u_i, u_i) = a_i$. $a_i = (z_i, z_i) = |z_i|^2$. Тогда $\sigma_i = \sqrt{a_i} = |z_i|$. Тогда $v_i = \dfrac{z_i}{|z_i|} \implies v_i = \dfrac{1}{\sigma_i}z_i$. Получили, что $v_1, \dots, v_r$ - ортонормированная система и $f(u_i) = z_i = \sigma_iv_i\ (i = 1, \dots, r)$, $f(u_i) = 0,\ (i = r + 1, \dots, m)$

Теперь докажем единственность чисел $\sigma_1, \dots, \sigma_m$. Рассмотрим матрицу отображения $F$ в базисах $u_i$ и $v_i$. $[f] \begin{pmatrix}\sigma_1 ^ 2  & 0 & \dots & 0 & 0\\ 0 & \sigma_2 ^ 2 & \dots & 0 & 0\\ \dots & \dots & \dots & \dots &  \\ 0 & 0 & \dots & \sigma_r ^ 2 & 0  \\ \dots & \dots & \dots & \dots  & \dots \\ 0 & 0 & 0 &0 & 0\end{pmatrix}$, $[f^*] = \begin{pmatrix}\sigma_1 ^ 2  & 0 & \dots & 0 & 0\\ 0 & \sigma_2 ^ 2 & \dots & 0 & 0\\ \dots & \dots & \dots & \dots &  \\ 0 & 0 & \dots & \sigma_r ^ 2 & 0  \\ \dots & \dots & \dots & \dots  & \dots \\ 0 & 0 & 0 &0 & 0\end{pmatrix}$. При этом первая матрица размера $m\times n$, а вторая - $n\times m$. Поэтому $[f\circ f^*] = \begin{pmatrix}\sigma_1 ^ 2  & 0 & \dots & 0 & 0\\ 0 & \sigma_2 ^ 2 & \dots & 0 & 0\\ \dots & \dots & \dots & \dots &  \\ 0 & 0 & \dots & \sigma_r ^ 2 & 0  \\ \dots & \dots & \dots & \dots  & \dots \\ 0 & 0 & 0 &0 & 0\end{pmatrix}$ - матрица $n\times n$.  При этом $\sigma_1 ^ 2, \dots, \sigma_r ^ 2$. Осталось заметить, что собственные числа определяются однозначно, так как мы по условию брали их положительными. При этом $\sigma_1, \dots, \sigma_r$ называются ==сингулярными числами==. Для определённости можно упорядочить их по убыванию.

### Теорема о свойствах наибольшего сингулярного числа.
**Теорема**
Пусть $L_1, L_2$ - конечномерные пространства со скалярным произведением. Пусть $f: L_1 \mapsto L_2$ - ненулевое отображение. Тогда $\forall x \in L_1: |f(x)| \leq \sigma_1|x$, где $\sigma_1$ - наибольшее сингулярное число.

**Доказательство**
Возьмём $\sigma_1 \geq \sigma_2 \geq \dots \geq \sigma_r$ - сингулярные числа. Тогда $u_1, u_2, \dots, u_m$ - соответствующий ОНБ из собственных векторов. Пусть $x = a_1u_1 + \dots + a_m u_m$. Тогда $f(x) = a_1f(u_1) + \dots + a_m f(u_m) = a_1\sigma_1 v_1 + \dots + a_r\sigma_r v_r =$ $= a_1\sigma_1 v_1 + \dots + a_r\sigma_r v_r$. Так как $v_1, \dots, v_r$ - ортонормированная система, то $|f(x)|^2 = (f(x), f(x)) = (a_1\sigma_1 v_1 + \dots + a_r\sigma_r v_r) =$
Ребятки, записать не успел, наблюдайте скриншот Расина.![](attachments/Pasted%20image%2020230410163134.png)
![](attachments/Pasted%20image%2020230410163424.png)

**Следствие**
Наибольшее сингулярное значение $\sigma$ это $\max\limits_{|x| = 1} |f(x)$.

### ??Что??
***

%%не очень понял, о чём конкретно говорит Расин%%
В соответствующих ОНБ матрица оператора $f$ имеет вид $[f] \begin{pmatrix}\sigma_1 ^ 2  & 0 & \dots & 0 & 0\\ 0 & \sigma_2 ^ 2 & \dots & 0 & 0\\ \dots & \dots & \dots & \dots &  \\ 0 & 0 & \dots & \sigma_r ^ 2 & 0  \\ \dots & \dots & \dots & \dots  & \dots \\ 0 & 0 & 0 &0 & 0\end{pmatrix}$. Продолжение с этого момента: ![](attachments/Pasted%20image%2020230410164457.png)
![](attachments/Pasted%20image%2020230410164950.png)

### Теорема о сингулярном разложении матрицы
**Теорема**
1) Пусть $A$ - матрица над $\mathbb C$. Тогда существуют положительные числа $\sigma_1 \geq \dots \geq \sigma_r > 0$ и такие *унитарные матрицы* $U$ и $V$ такие, что $A = V \begin{pmatrix}\sigma_1 ^ 2  & 0 & \dots & 0 & 0\\ 0 & \sigma_2 ^ 2 & \dots & 0 & 0\\ \dots & \dots & \dots & \dots &  \\ 0 & 0 & \dots & \sigma_r ^ 2 & 0  \\ \dots & \dots & \dots & \dots  & \dots \\ 0 & 0 & 0 &0 & 0\end{pmatrix} U$
2) Пусть $A$ - матрица над $\mathbb C$. Тогда существуют положительные числа $\sigma_1 \geq \dots \geq \sigma_r > 0$ и такие *ортогональные матрицы* $U$ и $V$ такие, что $A = V \begin{pmatrix}\sigma_1 ^ 2  & 0 & \dots & 0 & 0\\ 0 & \sigma_2 ^ 2 & \dots & 0 & 0\\ \dots & \dots & \dots & \dots &  \\ 0 & 0 & \dots & \sigma_r ^ 2 & 0  \\ \dots & \dots & \dots & \dots  & \dots \\ 0 & 0 & 0 &0 & 0\end{pmatrix} U$

**Доказательство**
Следует из предыдущего.

## Псевдообратное отображение

> [!question] Что это было?..
> Пусть $f: L_1\mapsto L_2$ - линейное отображение в пространстве со скалярным произведением. Пусть $m = \dim L_1, n = \dim L_2$. По теореме о сингулярном разложении существуют ОНБ $u_1, \dots, u_m$ в $L_1$ и $v_1, \dots, v_n$ в $L_2$. При этом для некоторого $r$ для всех $i \in 1,\dots, r$ $f(u_i) = \sigma_i v_i$ и $f(u_i) = 0$, если $i = r+1, \dots, m$. $\sigma_i$ - сингулярные числа, $\sigma_i > 0, 1 \leq i \leq r$. $f(u_i) = \sigma_i v_i,\ i = 1\dots r$. Рассмотрим для $L_2$ отображение $g(v_i) = \dfrac 1 {\sigma_i} u_i$, при $i = 1,\dots, r$. Рассмотрим отображение $f^+(y) = \begin{cases} g(y): y \in <v_1, \dots, v_r>\\ 0, y \in <v_{r+1}, \dots, v_n\end{cases}$


> [!abstract] Псевдообратное отображение
> Отображение $f^+(y): L_2 \mapsto L_1$ (см. выше) называется ==псевдообратным== к отображению $f$.

## Приложения сингулярного разложения
### Формулировка задачи
![](attachments/Pasted%20image%2020230418131608.png)
Пусть даны точки $M_1, \dots, M_n$. Нужно провести прямую таким образом, чтобы сумма расстояний от точек до этой прямой была наименьшей.


> [!abstract] 
> Пусть дано линейное пространство $L$, $M$ - его подпространство, $r$ - некоторый вектор. Множество векторов вида $r + M = \Pr + u : u\in M\}$ называется ==линейным многообразием== в $L$. При этом $M$ называется ==направляющим подпространством== для многообразия $r + M$. %%Держу в курсе, это было в прошлом семе%%

### Лемма о линейных многообразиях
**Лемма**
$r + M = s + M \iff r - s \in M$.

**Доказательство**
$\implies$. %%как сказал Расин: Ну, туда. Туда ваще легко доказать.%% $u \in r + M,\ s + M$. Тогда $u = r + m_1 = s + m_2$. Таким образом, $r - s \in M$
$\impliedby$. Расин сказал доказать самосотятельно.

### Теорема
**Теорема**
Предположим, что для любых векторов $x_1, \dots, x_n$ линейное многообразие $r + M$ имеет размерность $k$ и таково, что для любого многообразия $r' + M'$ размерности не более $k$ выполняется неравенство $\sum\limits_{i = 1}^n(\,d(x_i, r + M))^2 \leq \sum\limits_{i = 1}^n(\,d(x_i, r' + M'))^2$. Тогда $r + M = \dfrac {x_1 + x_2 + \dots + x_n}{n} + M$, <font style="color:#A6E3A1">где $\,d(x_i, r' + M')$ - длина ортогональное проекции вектора $x_i - r'$ на подпространство $M$.</font>

**Ljrfpftkmcndj**
Рассмотрим $s = \dfrac{x_1 + x_2 + \dots + x_n}{n}$. Пусть $w_i = x_i - s$ (ортогональная составляющая вектора $x_i - s$)
$\sum\limits_{i = 1}^n (x_i - s) = (\bar x_1 + \dots + \bar x_n - n\bar s) = \bar x_1 + \dots + \bar x_n - (\bar x_1 + \dots + \bar x_n) = 0$
В частности $w_1 + \dots + w_n = 0$, и, следовательно $w_n = -w_1 - \dots - w_{n-1}$

Пусть $r$ - вектор как в условии теоремы. Рассмотрим ортогональную составляющую $t = s - r$ на подпространство $M$. $x_i - r = (x_i - s) + (s - r) = w_i + t$. $\sum\limits_{i=1}^n (\,d(x_i, r + M))^2 = \sum\limits_{i = 1}^n (\,d(x_i - r, M))^2 =$ $=\sum\limits_{i=1}^n |w_i + t|^2 = \sum\limits_{i = 1}^{n - 1} |w_i + t|^2 + |w_n + t|^2 =$ $= \sum\limits_{i = 1}^{n - 1} |w_i + t|^2 + |-w_1 - \dots - w_{n - 1} + t|^2 =$ $= \sum\limits_{i = 1}^{n - 1} |w_i + t|^2 + |t - \sum\limits_{i=1}^{n - 1} w_i|^2 =$ $= \sum\limits_{i=1}^{n-1}\left ( (w_i, w_i) + (w_i, t) + (t, w_i) + (t_t)\right) + (t, t) -$$-\left(t,\sum\limits_{i = 1}^{n - 1} w_i\right)- \left(\sum\limits_{i = 1}^{n - 1} w_i,\ t \right) + \left(\sum\limits_{i = 1}^{n - 1} w_i,\sum\limits_{i = 1}^{n - 1} w_i \right) =$ $=\sum\limits_{i = 1}^{n - 1} |w_i|^2 + \left( \sum\limits_{i = 1}^{n - 1} w_i, t \right)+ \left ( t, \sum\limits_{i = 1}^{n - 1} w_i \right)+ ( n - 1)|t^2| + |t^2| -$$- \left(t, \sum\limits_{i = 1}^{n-1} w_i\right) - \left(\sum\limits_{i = 1}^{n - 1} w_i, t\right)+ \left(\sum\limits_{i = 1}^{n - 1} w_i, \sum\limits_{i = 1}^{n - 1} w_i\right)=$$=\sum\limits_{i = 1}^{n - 1} |w_i|^2 + n|t^2| + (w_n, w_n) =$$= \sum\limits_{i = 1}^{n - 1} |w_i|^2 + n|t^2| + |w_n|^2 = \sum\limits_{i = 1}^b |w_i|^2 + n|t^2|$


Поскольку у ортогональной составоябщей вектора $r$ длина наименьшая  по предположению, то
$$\sum\limits_{i = 1}^n |w_i|^2 + n|t^2| \geq \sum\limits\limits_{i = 1}^n |w_i|^2=$$$$= \sum\limits+{i = 1}^n \,d(x_i, s + M)^2 \geq \sum\limits \,d(x_i, r+ M)^2$$
Поскольку изначально раскладывалась правая часть неравенства и она совпадает с левой, то
$$\sum\limits_{i = 1}^n |w_i|^2 + n|t^2| = \sum\limits_{i = 1}^n |w_i| ^ 2$$


> [!ERROR] УРА
> ЭТА ШЛЯПА КОНЧИЛАСЬ
> ---




# Линейные и квадратичные функции и формы
## Билинейные функции

> [!abstract] Билинейная функция
> Пусть $L$ - линейное пространство над $F$. Тогда отображение $f: L\times L \mapsto F$ называется ==билинейным==, если:
> 1) $f(\alpha x, y) = f(x, \alpha y) = \alpha f(x, y)$
> 2) $f(x_1 + x_2, y = f(x_1, y) + f(x_2, y)$
> 3) f(x, y_1 + y_2) = f(x, y_1) + f(x, y_2)

### 
Пусть $a_1, a_2, \dots, a_n$ - базис $L$. Тогда $x = \alpha_1 a_1 + \alpha_2 a_2 + \dots + \alpha_n a_n$
и $y = \beta_1 a_1 + \beta_2 a_2 + \dots + \beta_n a_n$

$f(x, y) = \alpha_1\beta_1 f(a_1, a_1) + \alpha_1 \beta_2 (a_1, a_2) + \dots + \alpha_1\beta_n f(a_1, a_n)+$ $+ \alpha_2\beta_1 f(a_2, a_1) + \alpha_2 \beta_2 (a_2, a_2) + \dots + \alpha_2\beta_n f(a_2, a_n) + \dots$ $+\alpha_n\beta_1 f(a_n, a_1) + \alpha_n \beta_2 (a_n, a_2) + \dots + \alpha_n\beta_n f(a_n, a_n)$

Пусть $\gamma_{ij} = f(a_i, a_j)$. Тогда $[f] = (\gamma_{ij})$

$G = \begin{pmatrix} (a_1, a_1) & (a_1, a_2) & \dots & (a_1, a_n) \\ (a_2, a_1) & (a_2, a_2)  & \dots  & (a_2, a_n) \\ \dots & \dots & \dots & \dots \\ (a_n, a_1) & (a_n, a_2)  & \dots &  (a_n, a_n)  \end{pmatrix}$ - матрица Грамма %% а она нужна?%%

$f(x, y) = [x]^t[f][y]$

### Билинейные формы

> [!abstract] Формы
> ==Формой== называется однородный многочлен, то есть такой, что $f(nx) = nf(x)$


> [!abstract] Билинейная форма
> Многочлен от двух систем переменных, линейный по каждой из этих систем, называется ==билинейной формой==.

### Теорема о линейном пространстве линейных функций
**Теорема**
Линейные функции относительно операций сложения и умножения на элементы поля образуют линейное пространство.

**Доказательство**
$$\alpha (f + g) = \alpha f + \alpha g$$
$$\alpha(f + g)(x, y) = \alpha(f(x, y) + g(x, y)) = \alpha(f(x, y)) + \alpha(g(x, y)) = (\alpha f + \alpha g)(x, y)$$

При этом размерность пространства билинейных функций $n^2$, где $n$ - количество аргументов.

## Симметричные билинейные функции

> [!abstract] Симметричная билинейная функция
> Билинейная функция $f$ называется ==симметричной==, если $\forall x, y: f(x, y) = f(y, x)$. Матрица такой функции симметрична.

## Квадратичные функции

> [!abstract] Квадратичная функция
> $f: L\mapsto F$ - ==квадратичная==, если $\exists$ билинейная функция $g$ такая, что $f(x) = g(x, x)$. Тогда $f(x) = [x]^t [g][x]$

### Теорема:
**Теорема**
Для любой квадратичной функции существует единственная билинейная функция, из которой она получается

**Доказательство**
![](attachments/Pasted%20image%2020230424154926.png)

## Квадратичные формы

> [!abstract] Квадратичная форма
> Однородный многочлен второй степени от одной системы переменных называется ==квадратичной формой==. Матрица квадратичной формы - это матрица симметричной билинейной функции, из которой она получилась.

### Матричный вид
Легко проверить, что квадратичную форму $f(x_1, \dots, x_n) = a_{11} x_1^2 + \dots + a_{nn}x_n^2 + a_{12}x_1x_2 + \dots + a_{n-1\ n}x_{n-1}x_n$ можно записать в матричном виде $f = (x_1, \dots, x_n)\begin{pmatrix} a_{11}  & a_{12} & \dots & a_{1n} \\ a_{21} & a_{22} & \dots & a_{2n} \\ \dots & \dots & \dots & \dots \\ a_{n1} & a_{n2} & \dots & a_{nn}\end{pmatrix}\begin{pmatrix} x_1 \\ x_2 \\ \dots \\ x_n\end{pmatrix}$

### Невыдрожденная замена переменных
Даны наборы переменных $x_1, x_2, \dots, x_n$ и $y_1, y_2, \dots, y_n$. Тогда, если $x_1 = b_{11}y_1 + \dots + b_{1n}y_n$, $x_2 = b_{21}y_1 + \dots + b_{2n}y_n$, $\dots$, $x_n = b_{n1} + \dots + b_{nn}y_n$. Тогда мы имеем невырожденную замену $x = By$.

### Замечание о невырожденной замене
**Замечание**
Если к квадратичной форме $f = X^TAX$ применить невырожденную замену $x = By$, то получим квадратичную форму с матрицей $B^TAB$.

**Доказательство**
$f = (BY)^TA(BY) = Y^TB^TABY$

### Конгруэнтные матрицы

> [!abstract] Конгруэнтные матрицы
> Матрицы $A$ и $B$ ==конгруэнтны==, если существует невырожденная $C$ такая, что $A = C^TBC$. Очевидно, что отношение конгруэнтности является отношением эквивалентности. Таким образом, если одна квадратичная форма получается невырожденной заменой из другой, то их матрицы конгруэнтны.

### Замечание о конгруэнтных матрицах
**Замечание**
Конгруэнтные матрицы либо имеют определители равные нулю, либо одинаковых знаков.

**Доказательство**
$|B| = |C^TAC| = |C^T||A||C| = |C||A||C| = |C|^2|A|$

## Канонический вид

> [!abstract] Канонический вид
> Квадратичная форма имеет ==канонический вид==, если её матрица диагональна (или в самой квадратичной форме есть только квадраты.)

### Тоеорема о приведении к квадратичной форме
**Теорема**
Из любой квадратичной формы с помощью невырожденной замены переменных можно получить квадратичную форму в каноническом виде.

**Метод Лагранжа. Доказательство.**
1 случай. $a_{11} \neq 0$. Тогда собираем всё с $x_1$и получаем $f(x_1, \dots, x_n) = a_{11}x_1^2 + 2a_{12}x_1x_2 + 2a_{13}x_1x_3 + \dots + 2a_{1n}x_1x_n + a_{22}x_2^2 +$$+ \dots + a_{nn}x_n^2 + 2a_{23}x_2x_3 + \dots + 2a_{2n}x_2x_n + \dots + 2a_{n-1,n}x_{n-1}x_n$

Выделяем полный квадрат:
$f(x_1, \dots, x_n) = a_{11}x_1^2 + 2a_{12}x_1x_2 + 2a_{13}x_1x_3 + \dots + 2a_{1n}x_1x_n + f'(x_2, \dots x_n) =$

> [!error] Я черешня
> украдите у расина пожалуйста

2 случай. $a_{11} = a_{22} = \dots = a_{nn} = 0$. Тогда получаем квадрат перед $x_1$: делаем замену $x_1 = y_1 - y_2, x_2 = y_1 + y_2, x_3 = y_3, \dots, x_n = y_n$. Получаем квадратичную форму, у которой первая переменная в квадрате. Приходим к случаю 1.

Указанная замена будет невырожденной, так как $C = \begin{pmatrix} 1 & -1 & 0 & \dots & 0 \\ 1 & 1 & 0 & \dots & 0 \\ 0 & 0 & 1 & \dots & 0 \\ \dots & \dots & \dots & \dots &\dots \\ 0 & 0 & 0 & \dots & 1\end{pmatrix}$. Её определитель равен двум.

### Замечание о последовательности невырожденных замен
**Замечание**
Последовательность невырожденных замен является невырожденной заменой.

**Доказательство**
$X = BY,\ Y = CZ \implies X = BY = B(CZ) = (BC)Z$

**Метод приведения к главным осям**
Матрица квадратичной формы $A$ является симметричной $\implies$ у неё есть ОНБ из собственных векторов $\implies$ она диагонализирума. Тогда $A = T_{ES}DT_{SE}$. Матрица перехода невырождена, то есть замена невырожденная.

### Теорема: закон инерции квадратичных форм
**Теорема**
Если квадратичная форма над $R$ приведена двумя различными невырожденными преобразованиями к каноническому виду, то полученные формы имеют одинаковое число положительных, отрицательных и нулевых коэффициентов при квадратах.

**Доказательство**
Предположим, что мы привели квадратичную форму $f = X^TAX$ к каноническому виду $g = Y^TDY$. Пусть замена имеет вид $X = TY$, где матрица $T$ ортогональна (метод приведения к главным осям). В этом случае $f - Y^TT^TATY$, $g = Y^TDY$. Таким образом, $D = T^TAA^T$. Ранги матриц $A$ и $D$ совпадают, поэтому $\,r(AB) \leq \min\,r(A)\,r(B)$. Поэтому количество нулевых коэффициентов совпадает.

Предположим теперь, что форма $f$ приводится к каноническому виду невырожденной линейной заменой $x = Ty$:
$$f(y_1, \dots, y_n) = t_1y_1^2 + \dots + t_ky_k^2 - t_{k+1}y_{k+1}^2 - \dots - t_{k + 1}y^2_{k+1},$$
$$\ t_i > 0,\ i =1,\dots,k+l$$
Предположим теперь, что форма $f$ приводится к каноническому виду другой невырожденной линейной заменой $x = Sz$:
$$f(y_1, \dots, y_n) = s_1z_1^2 + \dots + s_pz_p^2 - s_{p+1}z_{p+1}^2 - \dots - s_{p + 1}z^2_{p+1},$$
$$\ s_i > 0,\ i =1,\dots,p+q$$

Таким образом, у нас $k + l = p + q$. Будем считать, что $k < p$. Замены переменных в общем виде:$$x = Ty:\quad\begin{cases}x_1 = b_{11}y_1 + \dots + b_{1n} y_n\\ \dots\\ x_n = b_{n1}y_1 + \dots + b_{nn}y_n\end{cases} \implies y = T^{-1}x$$$$x = Sz:\quad\begin{cases}x_1 = c_{11}z_1 + \dots + c_{1n} z_n\\ \dots\\ x_n = c_{n1}z_1 + \dots + c_{nn}z_n\end{cases} \implies y = S^{-1}Y$$$$\begin{cases}y_1 = d_{11}x_1 + \dots + d_{1n}x_n\\ \dots\\y_{n} = d_{n1}x_1 + \dots + d_{nn}x_n\end{cases}$$ $$\begin{cases}z_1 = f_{11}x_1 + \dots + f_{1n}x_n\\ \dots\\z_{n} = f_{n1}x_1 + \dots + f_{nn}x_n\end{cases}$$
Покажем, что существует ненулевой набор переменных $x_1, \dots, x_n$ такой, что $y_1 = y_2 = \dots = y_k = z_{p+1} = z_{p+2} = \dots = z_n = 0$.
Таким образом, получаем систему линейных уравнений:
$$\begin{cases} d_{11}x_1 + \dots + d_{1n}x_n= 0 \\
\dots \\

d_{k1}x_1 + \dots + d_{kn}x_n = 0 \\
f_{p+11}x_1 + \dots + f_{p+1n}x_n = 0 \\
\dots \\ f_{n1}x_1  + \dots + f_{nn}x_n = 0
\end{cases}$$
В этой системе $k + n - p < n$ уравнений, она однородна $\implies$ их бесконечно много, то есть существует ненулевое решение $x_1', \dots, x_n'$. Такому решению однородной системы соответствуют решения
$$\begin{cases}x_1' = c_{11}z_1 + \dots + c_{1n} z_n\\ \dots\\ x_n' = c_{n1}z_1 + \dots + c_{nn}z_n\end{cases} \implies y = S^{-1}Y$$ $$\begin{cases}x_1' = b_{11}y_1 + \dots + b_{1n} y_n\\ \dots\\ x_n' = b_{n1}y_1 + \dots + b_{nn}y_n\end{cases} \implies y = T^{-1}x$$
По предположению выше:
$$y_1 = y_2 = \dots = y_k = z_{p+1} = z_{p+2} = \dots = z_n = 0$$
А значит
$$y_1' = y_2' = \dots = y_k' = z_{p+1}' = z_{p+2}' = \dots = z_n' = 0$$
Тогда $$f(x_1', \dots, x_n') = f(y_1', \dots, y_n') = t_1(y_1)^2 + \dots + t_n(y_n)^2 =$$$$= -t_{k+1}(y_1)^2 - \dots - t_{k+1}(y_n)^2$$ $$f(x_1', \dots, x_n') = f(z_1', \dots, z_n') =s_1(z_1)^2 + \dots - s_n(z_n)^2 =$$$$ = s_1(z_1)^2 + \dots + s_p(z_p)^2$$
Таким образом, мы получили противоречие: при одинаковом наборе переменных получились числа разных знаков, которые по предположению должны быть равны.

## Эквивалентность квадратичных форм

> [!abstract] Эквивалентные квадратичные формы
> Квадратичные формы $f$ и $g$ называются ==эквивалентными==, если одна из них может быть получена из другой с помощью невырожденной линейной замены.

### Теорема об эквивалентности квадратичных форм
**Теорема**
Квадратичные формы эквивалентны тогда и только тогда, когда они имеют одинаковый положительный и отрицательный индекс инерции.

**Доказательство**
$\implies$ пусть $f\sim g$, т.е. существует невырожденная замена переменных $X = TY$, приводящая $f$ к $g$.
Пусть $Y = SZ$ - замена, приводящая $g$ к форме $h$, имеющей канонический вид.

$$X = TY = T(SZ) = (TS)Z$$
то есть $f$ приводится к $h$.
Таким образом, мы получаем, что $f$ и $g$ приводятся к одной и той же канонической форме, то есть положительные и отрицательные индексы у них совпадают.

$\impliedby$. Предположим, что $f$ и $g$ имеют одинаковые положительные и отрицательные индексы. Это означает, что $f$ приводится к форме $h_1$ заменой $X = TX'$, а $g$ приводится к форме $h_2$ заменой $Y = SY'$. Переименовав коэффициенты, можно получить $$h_1 = {a_1x_1'}^{2} + \dots + {a_kx_k'}^{2} -{ a_{k+1}x_{k+1}'}^{2} - \dots - a_{k+1}{x_{k+1}'}^{2}$$
$$h_2 = {b_1y_1'}^{2} + \dots + {b_ky_k'}^{2} -{ b_{k+1}y_{k+1}'}^{2} - \dots - b_{k+1}{y_{k+1}'}^{2}$$
Делаем замену:
$$x_1 = \sqrt{\dfrac {b_1}{a_1}}y_1$$
$$x_{k+1} = \sqrt{\dfrac{b_{k+1}}{a_{k+1}}}y_{k+1}$$
$$X' = UY'$$
Переходим линейной заменой от $f$ к $g$ $$f \to^T h_1 \to ^U h_2 \to^{S^{-1}} g$$


## Положительно определённые квадратичные формы

> [!abstract] Положительно определённая квадратичная форма
> Квадртичная форма называется ==положительно определённой==, если на каждом ненулевом наборе значений она принимает положительное значение

### Теорема о каноническом виде положительно определённой формы
**Теорема**
Квадратичная форма $f(x_1, x_2, \dots, x_n)$ положительно определена $\iff$ в любом её каноническом виде $t_1x_1^2 + \dots + t_nx_n^2\ (t_1 > 0, \dots, t_n > 0)$

**Доказательство**
$\implies$. Если форма приводится к такому каноническому виду заменой $X = TY$
$$f(x_1, \dots, x_n) = f(y_1, \dots, y_n) = t_1y_1^2 + \dots + t_ny_n^2$$
то получается положительно определённая квадратная форма

$\impliedby$$f$ - положительна определена, но при этом получаем $t_n < 0$. $$f(x_1, \dots, x_n) = f(y_1, \dots, y_n) = t_1y_1^2 + \dots + t_ny_n^2$$ при наборе $y_1  = \dots = y_{n-1} = 0, y_n = 1$ положительно определена.
$$f(0, 0, \dots, 1) < 0$$
$$\begin{cases} y_1 = d_{11}x_1 + \dots + d_{1n}x_n\\ \dots \\
y_n = d_{n1}x_1 + \dots + d_{nn}x_n\end{cases} \implies$$
![](attachments/Pasted%20image%2020230515163958.png)
$$\implies\begin{cases} d_{11}x_1 + \dots + d_{1n}x_n = 0\\ \dots \\
d_{n1}x_1 + \dots + d_{nn}x_n = 1\end{cases}$$

### Теорема: критерий Сильвестра

> [!abstract] Угловые миноры 
> Пусть $A$ - квадратная матрица, для каждого $k$ миноры, расположенные в первых $k$ столбцах, называются ==угловыми минорами==.

**Теорема**
Квадратичная форма является положительно определённой $\iff$ все угловые миноры её матрицы положительны.

**Доказательство из википедии**
Пусть $q(x)$  — положительно определённая квадратичная форма. Тогда $j$-й диагональный элемент положителен, так как $q(e_j) > 0$, где $e_j$ - вектор со всеми нулевыми координатами, кроме $j$-й При приведении матрицы к каноническому виду в силу невырожденности угловых миноров стро́ки не нужно будет переставлять, поэтому в итоге знаки главных миноров матрицы не изменятся. А в каноническом виде диагональные элементы положительны, а значит и миноры положительны; следовательно, (так как их знак не менялся при преобразованиях) у положительно определённой квадратичной формы в любом базисе главные миноры матрицы положительны.

$\impliedby$. Дана симметричная квадратичная форма, все угловые миноры которой положительны. Рассмотрим сначала первый диагональный элемент в каноническом виде: его знак определяется первым угловым минором. Далее, знак числа $\dfrac{\Delta_{i+1}}{\Delta_{i}}$ определяет знак $(i+1)$-го элемента в диагональном виде. Получается, что в каноническом виде все элементы на диагонали положительные, то есть квадратичная форма определена положительно.


**Доказательство из более надёжного источника**
![](attachments/Pasted%20image%2020230516130116.png)
![](attachments/Pasted%20image%2020230516130124.png)

**Доказательство Расина**
ТАМ $n\to\infty^{\infty^{\infty^{\infty^{\infty}}}}$ страниц, вы чего

# Квадрики на плоскости
## Эллипс

> [!abstract] Эллипс
> ==Эллипсом== называется множество всех точек плоскости, координаты которых в подходящей системе координат удовлетворяют ==каноническому уравнению эллипса== вида $\dfrac{x^2}{a^2} + \dfrac{y^2}{b^2} = 1,\ a, b > 0$. Система координат, для которой справедливо это уравнение, называется ==канонической==


> [!abstract] Вершины эллипса
> Точки $(-a, 0),\ (a, 0),\ (0, -b),\ (0, b)$ называются ==вершинами эллипса==


> [!abstract] Фокусы эллипса
> Число $c > 0$ такое, что $c^2 = a^2 + b^2$, называется ==фокусным расстоянием== эллипса, точки $F_1(-c, 0),\ F_2(c, 0)$ называются ==фокусами эллипса==


> [!abstract] Фокальный радиус 
> Для любой точки эллипса $M$ длины отрезков $|MF_1|$ и $MF_2|$ называются ==фокальными радиусами== точки $M$.


> [!abstract] Эксцентриситет эллипса
> Число $e = \dfrac c a$ называется ==эксцентриситетом эллипса==.


> [!abstract] Директрисы эллипса
> Прямые с уравнениями $x = \pm \dfrac a e$ называются ==директрисами эллипса==.

![](attachments/Pasted%20image%2020230516132523.png)

### Лемма
**Лемма**
Точка $M(x, y)$ принадлежит эллипсу $\iff$ её фокальные радиусы равны $r_1 = a - ex,\ r_2 = a + ex$

**Доказательство**
Из уравнения эллипса получаем $y^2 = b^2 - \dfrac {b^2}{a^2}x^2$
$$r_2 = |F_2M| = \sqrt{(x - c)^2 + y^2} = \sqrt{x^2 - 2cx + c^2 + b^2 - \dfrac{b^2}{a^2}x^2} =$$$$= \sqrt{x^2\left(1 - \dfrac{b^2}{a^2}\right) - 2cx + (c^2 + b^2)} = \sqrt{\dfrac{c^2}{a^2}} = e^2$$
Аналогично для $r_2$

### Теорема: фокальное свойство
**Теорема**
Точка $M$ принадлежит эллипсу $\dfrac{x^2}{a^2} + \dfrac {y^2}{b^2} = 1$ $\iff r_1 + r_2 = 2a$

**Доказательство**
$\implies$. $r_1 + r_2 = |F_1M| + |F_2M| = (a + ex) + (a - ex) = 2a$

$\impliedby$. Пусть теперь $M(x, y)$ для которой $|MF_1| + |MF_2| = 2a$.
$$\sqrt{(x - c)^2 + y^2} + \sqrt{(x + c)^2 + y^2} = 2a$$
$$\sqrt{(x - c)^2 + y^2} = 2a - \sqrt{(x + c)^2 + y^2}$$
$$x^2 - 2cx + c^2 + y^2 = 4a^2 - 4a\sqrt{(x + c)^2 + y^2} + x^2 + 2cx + c^2 + y2$$
$$-2cx = 4a^2 - 4a\sqrt{(x + c)^2 + y^2} + 2cx$$
$$a\sqrt{(x + c)^2 + y^2} = a^2 + cx \implies$$
$$\implies a^2 (x^2 + 2cx + c^2 + y^2) = a^4 + 2a^2cx + c^2x^2 $$
$$x^2(a^2 - c^2) + a^2y^2 = a^4 - a^2c^2$$
$$b^2x + a^2 y^2 = a^2(a^2 - c^2)$$
$$b^2x^2 + a^2y^2 = a^2b^2$$
$$\dfrac{x^2}{a^2} + \dfrac{y^2}{b^2} = 1$$
То есть $M$ принадлежит эллипсу.

### Теорема: директориальное свойство эллипса
**Теорема**
Точка $M$ принадлежит эллипсу $\iff$ отношение расстояния от $M$ до фокуса к отношению расстояния до соответствующей директрисы равно эксцентриситету

**Доказательство**
$\implies$. Возьмём правый фокус и правую директрису. $d = \dfrac{a}{e}$
$$d = |MD| = \left|\dfrac a e - x \right| = \left|\dfrac{a - ex} e\right|$$
$$\dfrac{|F_2M|}{d} = \dfrac{|a - ex|}{\left|\dfrac{a - ex}{e}\right|} = e$$

$\impliedby$. Пусть $M(x, y)$ - произвольная точка плоскости такая, что $\dfrac{|F_2M|}{d(M, l)} = e$.
$$\dfrac{\sqrt{(x - c)^2 + y^2}}{\left|x - \dfrac a e\right|} = e$$
$$\sqrt{(x - c)^2 + y^2} = e\left|x - \dfrac a e\right|$$
$$\sqrt{(x - c)^2 + y^2} = |ex - a|$$
$$x^2 - 2cx + c^2 + y^2 = e^2x^2 - 2eax + a^2$$
$$(1 - e^2)x^2 + y^2 = a^2 - c^2$$
После преобразований получаем уравнение эллипса, что и требовалось доказать.

## Гипербола

> [!abstract] Гипербола
> ==Гиперболой== называется геометрическое место точек плоскости, которые в подходящей системе координат удовлетворяют уравнению $\dfrac {x^2} {a^2} - \dfrac{y^2}{b^2} = 1$.


> [!abstract] Фокусное расстояние гиперболы
> Число $c > 0$ такое, что $c^2 = a^2 + b^2$, называется ==фокусным расстоянием== гиперболы.


> [!abstract] Эксцентриситет гиперболы
> Число $e = \dfrac c a$ называется ==эксцентриситетом== гиперболы, $e > 1$


> [!abstract] Асимптоты гиперболы
> Прямые $y = \pm \dfrac b a x$ - асимптоты гиперболы


> [!abstract] Вершины гиперболы
> Точки $(\pm a, 0)$ - вершины гиперболы

### Доказательство формулы асимптот
![](attachments/Pasted%20image%2020230520155113.png)

### Лемма: Cвойства фокальных радиусов
![](attachments/Pasted%20image%2020230520155943.png)

### Теорема: фокальное свойство гиперболы
**Теорема**
Точка $M(x, y)$ принадлежит гиперболе $\iff |r_1 - r_2| = a$

**Доказательство**
Доказательство тоже аналогичное вполне, и мы его с вами пропустим.

### Теорема: директориальное свойство гиперболы
**Теорема**
Точка $M(x, y)$ принадлежит гиперболе $\iff$ отношение расстояния от точки $M$ до соответствующей директрисы равно эксцентриситету

**Доказательство**
кто?

## Парабола

> [!abstract] Парабола
> ==Парабола== - множество всех точек плоскости, которые в подходящей системе координат имеют уравнение $y^2 = 2px$

### Теорема: директориальное свойство параболы
**Теорема**
Точка $M(x, y)$ принадлежит параболе $\iff$ расстояние до фокуса равно расстоянию до директрисы

**Доказательство**
$y^2 = 2px$. $F(\dfrac p 2, 0)$.
$$|MF| = \sqrt{\left(x - \dfrac p 2\right) ^2+ y^2} = \sqrt{\left(x - \dfrac p 2\right)^2 + 2px = }$$ $$= \sqrt{x^2 - px + \dfrac{p^2}{4} + 2px} = \sqrt{x^2 + px + \dfrac {p^2}4} = \left|x + \dfrac p 2\right|$$
## Классификация квадрик на плоскости

> [!abstract] Квадрика на плоскости
> ==Квадрикой на плоскости==, или кривой второго порядка называется множество всех точек плоскости, координаты которых в подходящей системе координат удовлетворяют уравнению второго порядка с двумя неизвестными. Уравнение имеет вид: $$Ax^2 + 2Bxy + Cy^2 + Dx + Fy + G = 0$$

### Теорема о классификации квадрик
**Теорема**
Любая квадрика на плоскости является либо эллипсом, либо гиперболой, либо параболой, либо парой прямых (пересекающиеся, параллельные, совпадающие), либо точкой, либо пустым множеством.

**Доказательство**
Половину доказательства Расина я не услышал, поэтому вот.  

> [!attention] Сюда смотри
> [Здесь нормальное доказательство](https://creewick.github.io/study/courses/algem/lectures/44.%20%D0%9A%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D1%8F%20%D0%BA%D0%B2%D0%B0%D0%B4%D1%80%D0%B8%D0%BA%20%D0%BD%D0%B0%20%D0%BF%D0%BB%D0%BE%D1%81%D0%BA%D0%BE%D1%81%D1%82%D0%B8.pdf)
> ![](attachments/Pasted%20image%2020230520164542.png)




# Квадрики в пространстве

> [!error] ВНИМАНИЕ
> Расин читал эту тему максимально неподробно (а писал я ещё менее подробно), поэтому я её УДАЛИЛ. Рекомендую отправиться прямиком сюда:
> http://kadm.kmath.ru/files/alggeom45.pdf
> http://kadm.kmath.ru/files/alggeom46.pdf
> http://kadm.kmath.ru/files/alggeom47.pdf
> 
> ![](attachments/Pasted%20image%2020230522161617.png)
> ![](attachments/Pasted%20image%2020230522161632.png)
> 
> ![](attachments/Pasted%20image%2020230522161641.png)

